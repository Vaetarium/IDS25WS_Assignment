start,end,text
3.28,31.22,"Okay, let's get started. Welcome to lecture number seven. Today we have one goal and it's very simple, right? I wrote a bunch of formulas on this slide and the goal is that you understand this, right? And you need to be able to apply it and you can only apply it if you actually know what these things mean."
31.22,59.6,"So please bear with me today. I will walk you through the complete derivation of these formulas in such a way that you really understand it. And then this is the hidden secret behind the neural network, right? This is in the end very simple if you understand how it works. So the agenda for today is that in the first lecture,"
59.6,90.99,"Last week on neural networks, I introduced what a neural network is. It's a bit disturbing if people come so late. Now they do not know what the goal is of today. So I already introduced a neural network and we looked if the weights have certain numbers, how you can do this feed forward. What we will focus on today is that if you have lots of training examples,"
90.99,119.28,"How do you update this new neural network? And that's the goal. After this lecture, we will be done with standard supervised learning techniques. Like what comes after this is unsupervised. How to evaluate these techniques. And we will start looking at special types of data like time series, event data, text data. And then we go into more, let's say, specialized topics."
119.82,149.62,"So let me repeat, because it's Monday morning, let's say, where we stopped, let's say, in the last lecture. I explained you what a neural network looks like. So we have a bunch of neurons. We also saw that if you want to express something as simple as an exclusive R in logic, you need to have, let's say, a hidden layer in the middle. And I gave you proof."
149.68,173.84,mathematical proof that that is impossible to do without having an extra layer in terms of these formulas. So we have outputs numbered y1 until yn. We have inputs numbered x1 until xd. And here we have one hidden layer in the middle. And typically we have many more.
173.84,203.68,"Just to explain the notation, this is sufficient, so you can imagine that there are multiple layers of these blue nodes, and they always have connections where a neuron of the previous layer is connected to all neurons of the next layer, but not more. So it always makes one step. So there are no connections, I don't know, from here to here, or something like that. It always goes just to the next layer, but it's fully connected."
203.68,225.3,"architecture that we assume, and what I showed you, let's say, in the lecture last Wednesday, was that you can think of this as function composition, right? Every layer is basically a function call, right? And you do this repeatedly, and that's how it works."
225.94,254.43,"Like if you have such a neural network and you have the inputs, it's very simple. You just multiply all the inputs with the corresponding weights and then you sum them, let's say, at every neuron. Then you apply an activation function and then there is an output that is given to the next layer. So we will see that again in more detail, but that's pretty easy. And we start by randomly assigning weights to..."
254.43,283.71,"We start by randomly assigning values to all these different weights. And if we do that, for a given input, we get certain predictions. But we are doing supervised learning, so we know what the output should be. And then, for every output neuron, we are comparing the, let's say, predicted value with the actual value. So it could be that, I don't know, these are the values that are predicted."
283.71,312.53,"These are the actual values. We have this error function. And today, again, you will see why it has this, let's say, odd structure. It has this odd structure because the derivative of this is very simple, right? It's just yk minus tk, right? If you take the derivative of it. So we compute the error using this function, right? So we take the difference, we square it, and we take half, and we sum up these things."
312.56,341.28,"And now the basic idea is that we, given a certain error, using gradient descent, we know in which direction we have to walk to reduce that error in a maximal way. Right? We want to walk down towards the error. So the goal is to lower this. And through, let's say, computing all the different derivatives, we know, let's say, how to update all the different weights. So for example, we..."
341.28,368.86,"we may decide to increase this weight leading to this number leading to a lower error. So that's the whole game. And if we have set this up properly, then we reach, let's say, a global minimum for this, let's say, basic problem. Of course, what I was just telling you about is that we have, let's say, one input and one output."
368.86,398.05,"But we have, of course, thousands of training examples, or millions of training examples. So we should not just compute this term, but we should do that for all the different instances. So we should compute the error not just for a single input, but we should sum over all the different inputs. And using the sum rule, when you apply derivatives, like this is very simple. It's a lot of work."
398.05,427.25,"But from a mathematical point of view, nothing really changes. So in most of the lecture, I will focus on just a single instance. And using the sum rule, you can then apply that for everything. And I showed you this picture before. So this is me. And this is like the steepest way down. That is the main idea. And these pictures are just, again, to put a mental image that you see what we are trying to do."
427.47,454.7,"So we randomize the weights. So we may have a neural network with millions of weights. We just randomly pick values for all the initial weights. And then we are here. We have a very large error. But we know how we should walk down to minimize the error. Easy, right? So last lecture we focused on this forward pass. So given an input."
454.7,483.82,"Like using these weights, we know the sum that comes into a neuron. We apply an activation function and then we pass it on. That's this forward behavior. And this backward behavior is that we go in the other direction. We have a certain error. And using the derivatives, we know how we should update all the different weights. So in one go, we update all the weights in the whole neural network. That's the way that it works."
485.01,513.01,"Okay? And please ask questions if things are not clear. So there are some things that I will not elaborate on, but that are things that I assume to be given. For me, the goal is only that you understand the principle. There are many types of neural networks. So you need to decide, how many layers do I have? How many neurons do I have in any, let's say, hidden layer?"
513.01,542.38,"Do I use a neural network with a special structure? So later we will see embeddings, but it is very weird. You start with a neural network that has many neurons, and then you try to pass it through a hidden layer in the middle, which is deliberately small. But at this point in time, we do not care. Based on some experience, we have decided the number of hidden layers and the number of neurons in every layer."
542.38,569.25,"So these are, let's say, meta decisions that we need to take before. Of course, the number in the input layer and the output layer are often given by the problem. So if we have a table with 10 columns of which one is the target feature, then we would have an output layer and the target feature would be, for example, binary. Then we would have one output neuron and nine input neurons."
569.25,595.82,"That would satisfy the problem. Next to deciding how many layers and how deep, how big they are, etc., we also often want to pre-process the data. Note that neural networks, just like with regression, is just dealing with numbers."
595.82,623.74,"If you have numbers that you have one feature that has a value, I don't know, between 0 and 0.1, and you have another feature that has values between, let's say, minus 10 million and plus 10 million, it's good to normalize this first, right? Otherwise, one thing will have probably much more effect. So we need to normalize, and we need to also encode categorical variables in terms of, let's say, numbers."
623.74,649.34,"So we again need to use, let's say, one hot encoding. So we also need to initialize the weights. Just assume that this is random. And we need to decide when and how to update the weights. And this is a topic that I will deal with at the end. So you should imagine that now we just look at a single instance. We just look at one instance and we want to update the network."
649.34,679.47,"But of course, you have millions of instances, so you have the choice to update it one instance at a time, or you have the possibility to update it for the whole dataset. It's something that we'll come back to later. As I said, we need to deal with, let's say, numbers. It's typically good to normalize the data, that there are not big differences between that. If there are categorical variables, we need to use one-hot encoding."
680.75,708.99,"And so if, I don't know, you have a variable that would be, I don't know, very bad, bad, neutral, good, very good, right? You could decide to encode that into a single number, right? From, I don't know, from minus one to one. But if you have things like, I don't know, cat, dog, elephant, then you need to use, let's say, something that is called one-hot encoding."
708.99,738.96,"that you've also seen before. So if you have an attribute x that has three possible values, what you do is that you introduce three variables, one for each. And if this variable holds, you set it to 1. If it doesn't hold, you set it to 0. So this would be the vector 0101001 to encode three possible values."
739.06,764.35,"Right? It's something that we have seen in earlier lectures before. So now our life is simple. Our input are numbers and our output are numbers. And we just want to train the network such that given the input numbers, we are able to predict the right numbers that come out. Right? So it's easy. So here's some more information."
764.35,793.5,"So we can do a numeric prediction. We can also do a classification. If it's binary classification, we can have one output neuron with values between 0 and 1. That's a bit when we talked about the XR problem, right? False was 0, true was 1. That would be something that is in this category. If you have, let's say, more than two values, so for example, dog, cat, elephant, cow, right? Then you need to use one hot encoding, right?"
793.5,823.23,"That's what I said before. As I said, we need to initially give these weights a number, just choose them in a particular interval based on experience. Now comes a more important thing, that if we have a neural network, then any weight is a variable. It's a parameter of our problem. So it's completely logical that if our number of training examples"
823.23,851.55,"is smaller than the number of parameters that we have, that doesn't make any sense. So what this slide says here, and you should take that with a grain of salt, because of course it depends on the problem, it depends on the characteristic of the data, is that the number of instances in the training set should be at least 10 times the number of free variables you have, to make sense."
851.55,885.82,"If they are at the same level, it does not make any sense. And more is better. The more training data that you have compared to the number of weights is good. So just to make this slide, because I think this is very important that you understand that. I should be more precise. Perhaps in my language I was not precise. So we are trying to compute a parameterized function."
885.82,912.54,"You can think of a neural network as a parameterized function where we just need to find the parameters. And these are these weights, right? So we just want to set these parameter values, right? And if you would like to learn a function based on examples and the number of parameters of that function is higher than the number of examples that you can train on, it does not make any sense because there will be..."
912.54,942.05,"I don't know, infinitely many solutions that would produce exactly the same result. Just imagine that, suppose that you have two data points, right, and you would like to learn a function, right? Suppose now that you have a function that is of the form, I don't know, a times x to the power 6, b times x to the power 5, c times x to the power 4, et cetera, et cetera, right? You would have such a formula."
942.05,971.36,"and you would have just two points, that would be incredibly stupid, right? Because if you have two points, the best prediction that you can make is a straight line through these two points, and not some wobbly line that goes like this, right? So this is unrelated to the number of variables in the table, right? The number of variables in the table, perhaps if I show you this."
971.36,1001.18,"So the number of, let's say, columns in the table is this plus this. So if we think of our input as a table, then for every instance we have the input features and the output features. That's not what I'm talking about. I'm now talking about the number of rows. That is the number of examples that we have in comparison to the amount of free variables that we have here. So I'm not talking about features."
1001.18,1032.8,"I'm talking about parameters of the function, the weights, how many different weights we have, right? Therefore, I show you, let's say, a number example. Perhaps that helps for you. So suppose that I have this neural network, which is very simple, right? Because we have just one internal hidden layer. So if we have D inputs, we have K outputs."
1032.8,1062.45,"And we have m number of internal things. So how many parameters does this function have? How many free parameters that we can set? So it's simply counting how many weights we have here and how many weights we have here. And if you write that down, that is equal to d times m."
1062.45,1091.23,"With this plus 1 comes because every one of these has a constant coming in. And the same here, right? So the number of, let's say, weights that we have here is m times n. And for every, let's say, output neuron, we also have this constant coming in. Right? So this is the number of parameters. And our rule of thumb that we should take with a grain of salt says we need to have at least 10."
1091.23,1114.0,of these instances. So if I now fill this in and I hope that you realize that what the issue now is that if you have something like this and I for example set all we have 10 inputs we have 10 outputs for example because we have a categorical variable with 10 possible outputs
1114.03,1142.61,"So D is equal to 10. N is equal to 10. We have, let's say, 10 neurons in the hidden layer. We need at least over 2,000 rows in our table for the problem to make sense. So that is why it is very tempting to use a huge neural network, because it's very expressive. But the bigger you make the neural network, the more training examples you need to have."
1142.61,1168.67,"Right? There is a trade-off between these things. Yeah? Does this help? This is one-handed layer, but you could make exactly the same, like if I would repeat this one, this layer, right? Like I would have an other internal one, like it would be the same as this one. Right?"
1168.67,1199.52,"It doesn't grow exponential in the number of layers that you have. It grows linear in the number of layers that you have. Right? Because it's just the sum of all the things. Yeah? Okay. So this is the problem that we always see. So if we have a data set, then there is the challenge between overfitting and underfitting. Right? So if we have lots of points and we just assume it is a straight line that is not very useful,"
1199.52,1229.22,"But this is also not, like if I have a high dimensional neural network, I can train the neural network to follow the blue line. But it will not work very well on unseen training examples. Because it's overfitting the data. So let's get into the details. So here you see a slide that I hope brings you back to high school. With, let's say, the different formulas for the derivatives."
1229.22,1259.07,"So one rule that we use all the time is the chain rule. I think on the next slide I have some more explanation of that. There's also this exponential function that has a very, let's say, special property. If you compute the derivative of e to the power x, it is still e to the power x. What we are using also in the end is that is the sum rule. So if we have multiple functions depending on x and we sum up these different functions,"
1259.07,1288.54,"then we can basically compute them all individually and then sum them up. So this is the rule that we are going to use at the end when we sum up over all the different instances. This rule allows us to focus on just a single instance all the time, because in the end we can apply this rule. So what is the idea of a derivative? And it is related to this gradient descent walking down. So at a particular point,"
1288.54,1317.18,"like you can see in which direction you should walk to reduce the function maximally or to increase the function maximally. That's the idea. So a bit more about the chain rule that you see here, because we apply that frequently. So if we have a function that is composed of other functions, what we can do is that we can first take the derivative of f, assuming..."
1317.18,1345.73,"that gx is a variable. So just think of gx as y. So we first compute this. And we multiply then. So here, like in the first phase, this gx is like a black box, like a single variable. And then in the second step, we take the derivative of gx. And this is something that we use all the time. And if I write it like this, then suggestively..."
1345.73,1375.38,"although there is more behind it, then you can see the logic behind it, right? That these two terms, they kind of remove each other, right? Just to have the intuitive idea. Yeah, clear? Just because for many of you, this is probably, let's say, rusty. So if I take an example where fy is equal to y to the power n,"
1375.38,1404.45,"And gx is equal to x to the power k. Now I compose this function. So I have a function ax that does this. Then I have x to the power k. That is the application of gx. And then I do that to the power n. And if I have x to the power k to the power n, then that's the same as multiplying n and k. So we all know that. Let's now check whether this rule..."
1404.45,1430.7,"actually holds, right, for this particular example. So I first, let's say, compute the derivative based on this expression, then using the power rule, like this is n times k times x to the power nk minus 1, right, so this is, let's say, if we do this directly."
1431.09,1461.68,"And if we do that by applying the chain rule, that's what I show you here, then we first take the derivative of f treating gx as a y, as a variable. So gx was equal to x to the power k, right? So we get this n times x to the power k to the power n minus 1. So this is this part."
1461.68,1490.69,"And then in the second phase, we take the derivative of g with respect to x. And that's very simple, right? That is this formula. And now I write it down. And surprise, surprise, these two expressions are exactly the same, right? Which gives you, and you could apply it with another example, right? And then you can see that this rule actually holds, right? That we're based on an example. So these two are equal. So here it doesn't make sense."
1490.69,1520.42,"to do this in this stage way, but later we were constantly in situations where we have a function h and we try to decompose it into different parts. That's something that we use repeatedly. Here I use it with, let's say, concrete values, let's say 2 and 3, the same thing, and you can see that this holds. So that is a brief refresher of"
1520.42,1549.07,"of, let's say, derivatives. You never thought that would be useful, but the same as linear algebra, but in the world of, let's say, machine learning and AI, I don't know, statistics, linear algebra, and these types of things are suddenly, let's say, the core of everything. So it's important that you really understand this. So this is the layered architecture that we are using."
1549.07,1574.69,"I'm constantly repeating this, and I'm constantly also using i, j, and k, using these conventions to give you some structure, right? That you understand what it is. What comes into a neuron is always the weighted sum of the inputs, right? So if this would be j, then this is what comes in. And what goes out is that we apply an activation function."
1574.69,1603.31,"to this AJ, and then we get an output ZJ. And then it goes to the next layer. So this is focusing now on a single neuron. So we look at a single neuron. AJ is the weighted sum of the inputs. So the previous layer has produced outputs that are here indicated with ZI. So this would be Z1, Z2, Z3, ZI."
1603.31,1629.58,"until, let's say, some ZM or whatever. And then we look, what comes into this neuron is the weighted sum of all of these things. So what comes in here is depending on all of these previous neurons in a weighted sense. And then this comes in, and then we apply an activation function to this AJ, and then this comes out."
1629.71,1655.17,"And we are using this sigmoid function that we have also seen in logistic regression. And we need to have something like this because we need to have a surface that we know which way to walk down. If we would have functions like in my previous lecture that are very, let's say, binary, we cannot use this trick of gradient d descent. Yeah, so..."
1655.17,1684.06,"AJ goes in, that is the weighted sum, and then we apply the sigmoid function to AJ, and this is the expression that you have here. So this is the basic principle. So from now on, although there are many other possibilities that you could take, we always assume also, let's say at the exam at the end, that we are using the sigmoid function as our activation function."
1684.06,1714.67,"And why do we do that? Because it has nice mathematical properties that I will show you later. So remember that it looks like this. So it has this very, let's say, nice feature that numbers between minus infinity and plus infinity are always scaled to something between 0 and 1. So that's the property. And it's also a function where we always know what to do to walk down."
1714.67,1745.02,"I think you can also imagine we are looking for a global minimum, and then a function like this is also very good, right? That is like monotonously going down, right? That has all kinds of advantages. So as I said, there are other activation functions that you see here. So in the previous lecture, we were using this one just to explain logical things in terms of zero and ones, but this is not really working if you use gradient descent."
1745.02,1772.43,"you need to have something that looks like this. There are some other functions that could be applied. So again, and I'm repeating things so that it sets into your mind. So we are looking at the neuron. What comes in is the weighted sum. And what goes out is, let's say, this sigmoid function applied to the weighted sum. That's it, right? And I'm showing you here one neuron."
1772.43,1805.42,"And we will often reason from one neuron, but we have a whole network, right? This neuron could be in any layer. Yeah? What is our goal? So this is a single neuron. What is our overall goal is to minimize this error. So we are interested in a derivative of this error that is equal to zero. And we know in which way that we should walk down. Here I'm showing this that, of course, we should sum this over all instances Q."
1805.49,1834.8,"We do not have just a single training example, but millions of training examples. So we need to take the sum over millions of samples, and that's like I'm parameterizing here, let's say, y and t with this particular instance that we look at. Using the sum rule, we see that the derivative of this can be simply written as the sum of all the derivatives."
1834.8,1864.67,"And because that is the case, we now just assume that there is just a single instance. I dropped a subscript Q here. There is just a single instance. And we will come back to that topic at the end. So our goal is now to update this for a single instance. A notational point that I need to mention, I also did that in the last lecture, is that sometimes you see this constant B."
1864.67,1892.86,"For example, in the SVMs, we had this constant B. But you can think of this constant B as a weight W0 that is multiplied times an input 1. So in all of the neural networks, you will see, let's say, an arc coming in like this. It is labeled with W0 something. So every neuron has such a constant B."
1892.86,1921.74,"And that is simply represented as another weight. Right? To make notation simple. And you should think of this as there is another input neuron here that has always value 1. Right? We do 1 times this value and then it's exactly the same as all the other ones. Yeah? So when I write down this sum here, right, I'm not having a special case for this situation."
1921.87,1950.45,"I just assume that Z0 is equal to 1. And that's like it's a constant 1 and that's the trick. Okay, so I'm abusing notation a bit to not make you completely, let's say, mad. So what we often do is that we use indices to refer to things in a different layer. So here I say ZI and here I said ZJ."
1950.51,1979.7,"But I and J are referring to a different layer, right? And I do not want to subscript Z also with a layer, right? I showed that in the previous lecture, but that would completely make you, let's say, mad, right? You would not be able to see anything. So when I'm using the terms ZJ or AI or something like that, we are always referring to these, let's say, layers that we have here."
1979.7,2009.76,"So a neuron has an input, the layer where the neuron resides itself, and an output layer. Just that you do not try to interpret too much into that. So what is now our goal? This was the error function. These are the formulas that I repeated. And our goal is very simple, right? We want to see how can we reduce the error. So we want to find, let's say,"
2009.76,2039.55,"If we are nudging this weight, so we are changing this weight, what effect does this have on an error? And think of a derivative. What does this mean? If I would make a very, very tiny change to this vector, sorry, to this value, a super small change to this value, then I can see what the effect on the error is. So if I increase, so if this is a positive number,"
2039.55,2070.54,"then that means that if I increase this, I increase the error. Right? And we want to reduce the error. That's why there is this minus here. Right? So Eij is basically telling us in which direction we should update the weight to reduce the error. Looking at just a single arc in our entire network. So we look at what is the..."
2070.54,2100.98,"What is the effect of changing this weight just a tiny bit on the error? And we want the error to go down, and that is explaining the minus. Clear? That's the basic idea. So, now, if we have a certain, like an arc that has a particular weight, then the new weight will be the old one plus this. And how to update this is informed by this."
2101.55,2130.91,"But we need to determine the step size. We need to determine, let's say, how big the change is that we want to be. And so this only gives us a direction. Is the effect of changing this weight, is it positive or negative? And you can also see how strong the effect is of changing this. But we do not know how big the step is. And so think of this, you're walking down a mountain and you're making, let's say, steps."
2130.91,2160.5,"And you can make many smaller steps into a particular direction or you can take very big steps. And in principle, if your step is too big, right, then you're kind of stepping over the valley, right? You're stepping from one mountain to another mountain, right? So that's why we have L and that is this learning rate. So think of L and L is again like something that is based on experience."
2160.5,2190.48,"So this is a learning rate or scaling parameter, and the goal is to reduce this error. What typically happens is that we start with a larger value of L. In other words, we start with bigger steps, and then we later go to smaller steps. Okay, so now I've set the scene. We want to reduce this, and we want to see the pipeline of how is this weight."
2190.58,2219.5,"influencing this error. And that's the only thing that we need to know. So if this weight is increased or decreased, what kind of effect does it have on the error? Because if we know that, we know how to update, let's say, that weight and reduce the error. It's very simple. And this weight is influencing only, and mark my word only,"
2219.5,2248.66,"If I modify this weight, I'm only changing AJ in the next layer. I'm not changing any neighbors of J. I'm just influencing J. And if I influence J, I'm just influencing ZJ. Because this only has an effect on this one. And then if I change something like this, in the end it has an effect on this."
2248.66,2278.0,"So this is like the chain of how the effect is being passed. And now the only thing that we need to do, so here I repeated all the formulas that I showed you before. The only thing that we need to do is to compute this. Simple, right? That's the idea. But to put this into, let's say, the concrete things that I was showing you on this sheet."
2278.0,2307.89,"right, we now need to, let's say, solve this expression. And there are two, as you can see on this sheet, there are two situations, right? And therefore I'm rewriting the problem several times to get down to these two, let's say, core situations. So using the chain rule that I explained before, let's say this derivative, so the fact of nudging,"
2307.89,2338.78,"weight ij on the error, can be rewritten in this way. And if I go back here, see this relationship here. So this error, this derivative, can be rewritten like this. And the green part is easy, and we do not need to do any case distinction. For the red part, it's more complicated, and we need to look at two situations."
2338.78,2370.0,"whether we are in the last layer or somewhere in the middle. So let's first look at the easy part, the part that is there in green. And this part here in green is looking at what is the effect of changing weight ij on aj. The naming is a bit weird, but you see what I mean. So we want to have this term. And that term is actually very easy."
2370.0,2399.1,"So we first focus on this. So what effect does changing this weight have on this? It is not influencing any of the other arcs going in. So any of the other arcs going in are like constants. We only change this arc. And that means that the only thing that is influenced by this is, so this part is a constant."
2399.1,2428.18,"For all the arcs coming in that are not equal to i, right? All i primes that are not equal to i, this is constant. And only this part is actually depending on this weight. So we can ignore this in the derivative and we just need to take the derivatives of this part. And we are changing weight wij, right? So this is simple that this is the..."
2428.18,2459.22,"derivative of this function. So in other words, the effect of changing wij is influencing aj with the factor zi, which is logical because that is like we multiply this number with that number. Do you see that? It's simple. So if we have the derivative of ax, the derivative is a."
2459.22,2487.54,"Right? That's the thing applied. So now we have a nice expression for this one and we fill that in here. Right? So now like this part is already solved. I copy that to this slide. Right? So we now know that this is this. So now we have this part that is unknown. And for this part, because that is more complicated to compute,"
2487.54,2527.38,"We use, let's say, this expression for it. So EJ is equal to minus the derivative of the error with respect to AJ. Yeah? Sorry? No, it's not a value. It's a function. It's a function depending on all the weights. Right? And we are nudging weights and see what the effect is. Right? So we are just looking at derivatives. We are not looking at concrete values. Right?"
2527.86,2560.16,"So, this green part was easy, the red part is more difficult, and that's why we use this expression. And the intuition that you should have here is, what is the effect of changing the weighted sum that goes in on the overall error? If we were able to influence this weighted sum here, what is the effect on the overall error?"
2560.16,2588.69,"That's what we need to do. And again, we can use our chain rule, right? So it's very nice. That's why I spent some time in the beginning explaining that to you again. So if we want to compute what the effect of changing AJ on the error is, that is the same as this. And why is that the case? This weighted sum is only influencing the error through ZJ."
2588.69,2620.58,The only connection between what goes in here and the error that may be 10 layers further is only effectuated through this ZJ. So we can rewrite this again using the chain rule. And now again we have two parts. So we have let's say this part and we have this part. And this part is also very easy.
2620.58,2647.95,"If you compute this derivative, and I will show you that in a minute in step by step, but for now just accept that the derivative that I compute here is the derivative of this formula that leads to this. So now this term that I have here can be replaced by this term. And this is the reason why we are using the logistic function."
2647.95,2675.98,"Note that we are taking the derivative of a logistic function with respect to changing aj, and it leads to this super elegant expression. So now we can fill in this by that. So again, we make our problem, let's say, more concrete. So I've now filled in, let's say, this derivative, and we have this."
2676.69,2702.61,"So the only part that is still unknown is this part, right? Because we know that Eij is equal to Ej times Zi. That's what we computed before. We know that this term is equal to that. So the only part that is missing in our whole machinery is this. Do you see that? Store this formula in your mind. There is a start here, right?"
2702.8,2730.99,"because I first want to explain you, let's say, more clearly why we got this. And then I will continue with this one. So what is the derivative of this? And it's not complicated. It's unrelated to, let's say, neural networks. It's just, let's say, applying, let's say, high school mathematics. So the derivative of this is that we first apply the chain rule again and assume..."
2730.99,2760.67,"And so just think of this as y, right? And if we take the derivative of 1 divided by y, that is y to the power minus 1. And the derivative of that is equal to, let's say, minus 1 divided by y to the power 2. Right? So high school mathematics, the derivative of 1 divided by y is like y minus 1. If I take the derivative, that is minus 1 times..."
2760.67,2790.7,"y to the power minus 2. Right? And that's what I did here. I just think of the green part as y. But using the chain rule, of course, I also need to take the derivative of y itself. So this is this one. And if I look at this, this one is a constant. And now again, I can apply the chain rule here. Right? Because I have e to the power a minus 1. Now I think of this as e to the power, let's say, z."
2790.77,2821.3,"And I compute the derivative where z is equal to minus aj. So e to the power something, e to the power z, and the derivative of that is still e to the power z. So this doesn't change here. But we still need to take the derivative of this function. We apply the derivative of this. So minus aj, what is the derivative of minus x, is equal to minus 1."
2821.3,2850.35,"Then we get this. So here you can see the rules that I applied. So now we have a complete expression where I applied the chain rule twice. And now I can rewrite as minus 1 times minus 1 is simply 1. I can move this to the top, etc. I can now also rewrite this into this part. Note that I..."
2850.35,2880.11,"divide by this to the power 2, so I can separate one of them, and then I have e to the power minus aj divided by 1 plus e aj, right? And I can rewrite this in this way. Did you see that? So here, I'm not doing something sophisticated, just let's say I'm using some mathematical rewriting. So now we have this, and now we see something that is really beautiful."
2880.11,2909.36,That's why I did it like that. Remember that Zj was equal to that. And what do we see here? Here we have Zj. And here we have Zj again. So I can rewrite this into this part. Do we see that? So this is the derivative of the sigmoid function when we vary Aj. And the derivative is shown here again.
2909.36,2942.24,"So this is one of the reasons why we use the sigmoid function, because it had such an elegant property. Remember, we get this term, and now we continue where we left out before. So this part came from what we have seen before, and this zi came, let's say, from the expression that we have seen earlier. So the only part that is still missing is this part. Are you still with me?"
2942.24,2970.67,"So this is left to compute. And now, until this point in time, we didn't care whether it was like a neuron in the output layer or a neuron in the middle. I did not use any of these properties. But now I'm forced to do case distinction between are we already at the end or are we somewhere in the middle. And it's called backpropagation. So we start at the end and then we propagate."
2970.67,2999.18,"the updates and the errors, let's say, backwards. So here I just repeated what I showed you before. This is the term that we are after. This is just a repetition of the expressions that we have seen earlier. And now just look at this formula. We are interested in the effect of changing Zj on the error. If we are at the end,"
2999.18,3028.69,"So we are looking at an output neuron. This is very easy, because this is our output, Zj, and this is the feature that we would like to have. So this is very easy. And note that if we are at the end, the final neuron is only influencing one of these output features, because it's dedicated to a particular feature."
3028.69,3056.18,"So this is the situation that we have now here, and it should be clear that Zj is only influencing Tj and not any of the other ones. So using this insight, I now compute this derivative, the one that we are after. So I fill in the error function, and I didn't change anything, it's just the error function that we had before."
3056.4,3084.66,"So this is the error function. We want to have the derivative and we are changing only Zj. Note that all the Zj's, the other ones are irrelevant. So this one is only influencing this one. So we can focus completely on this term because all the other terms are not influenced by changing Zj."
3084.94,3115.47,"So only this term is being influenced. So this is a constant, I can remove it, I look at the derivative of this, and this is why we always write error in this way, because it now simply becomes this. So this is half to the power, I don't know, x to the power 2, and et cetera, apply the chain rule, and this is what comes out. So the effect of changing zj,"
3116.5,3146.74,"The effect of changing Zj on the error is this, which is because of our carefully chosen error function, this looks very elegant. If we simply say we take the sum of all the errors, we would not have gotten such a simple expression. Problem solved. I can now fill in, let's say, all the different things."
3147.22,3175.31,"So we simply get this expression here that is there and we have ej and we have all the values, right? Because that was the only part missing. So by combining this with the earlier formulas, we see this and we see this as the change that we need to make where we are multiplying it with this, let's say, factor L, right? As I said, we are just applying, let's say, now..."
3175.6,3206.78,"the combination of all of these different formulas. Right? Clear, this part? There is a special case that I kind of skipped over that was this one. Right? I was always talking about earlier neurons. But this one has a constant 1 multiplied by this. So what we know is that Z0, the one that goes in here, is equal to 1. And that means that for this special weight,"
3206.78,3236.24,"We can simply fill in the number 1 here and we get this. So just a simplification, one of the terms zi is disappearing in this setting. So that was the situation where we are at the very end. Now we look at the situation and then you also understand why I took so a lot of effort to cleanly define all these different things."
3236.24,3268.42,"Now we are applying a kind of recursion. So now we look at something in the middle. And this is not an output layer. This is now a hidden layer. So J is now in a hidden layer. And we are interesting, so we are still just left to compute this term. So what is the effect of changing ZJ on the error? What is the effect of changing ZJ?"
3268.42,3294.26,"on the error. And there may be a whole network behind it, right? There may be 10 layers after this. But because of the notations that we showed, we can now, let's say, apply it in a recursive way. So let's just focus on this part. So Zj, if I'm changing that, I'm potentially changing all the..."
3294.26,3323.6,"the weighted sums that go in all of the neurons in the next layer. So we are not influencing one neuron, we are influencing all the neurons. If we change Zj, we are impacting everything in the next layer. However, we know that if we are changing this, like the other inputs that are going into the next layer are not changing. So here it is kind of..."
3323.6,3350.69,"saying what I just said. So a change in Zj impacts all Ak's, right? But if I look at a particular Ak in the next layer, it is only influenced by Zj. The rest is constant, right? And that's what we are using when we compute the derivatives. So let's again apply, let's say, the sum and chain rule."
3350.69,3382.93,"So here we are interested in the effect of Z, J and error. Using the sum rule, we can simply say, okay, let's take a look at all the, so when we have multiple output neurons, is it impacting all of these things? We use the sum rule for that. So K is ranging over all the output neurons in the next layer. And we split that into this part. So again, chain rule."
3382.93,3410.93,"We know that ak is equal to this, so we rewrite it in this particular way. Again, these two terms are, let's say, changing each other. Again, we have two terms, this term and this term, that we need to compute. Now we can apply recursion, because we have defined ej to be equal to this."
3411.12,3440.45,"And if I replace j by k, you can hopefully recognize that the same term is appearing here. Right? So, in other words, we already know this. So, we only have to compute that. Yeah? So, this part, as I just indicated, we know already what it is because we have an expression for that. And, like, there is a minus here. But there is also a minus here. Right? So, we need to rewrite that like this."
3440.45,3472.85,"So this can be rewritten to this. And this minus is removing this minus. The only thing that remains to be done is this part. Yeah? It's called backpropagation. Right? And it's called backpropagation. So we can now assume, because we started with the output layer, and now we are working our way inwards. Right?"
3472.85,3502.51,"We come from the back and we go to forward. So we can assume that we already know this. Because if this was the last layer, we have this expression. If it's not the last layer, we can look at the layer before and first solve that and then go to the next layer. So we can assume that we already know all the EK values for all the neurons here. Because we start at the back. It's like..."
3502.51,3532.67,"induction, right? We start with case 0, that's the end, and now we walk our way backwards, right? To the beginning. So that allows us to assume that we already know this, right? Because first is the output layer and etc. So we now have this, right? And the thing left to compute is this, but that's very simple, right? So we now"
3532.67,3559.42,"I'm just repeating what I had before. If you look at this, what is the effect of zj on k? All the other inputs are not changing. The only thing that is changing is this term times that term. So we can rewrite this into, let's say, this expression, which is equal to simply the weight wik."
3559.42,3589.36,"So now we can fill out this value and now we are really done. We have, let's say, closed expressions for all of them. And I realize it's very difficult for you to keep track. That's why I'm constantly, let's say, repeating all the formulas that we have here that we kind of do this step by step. So here I'm, let's say, putting all of our knowledge and we get, let's say, this expression for EJ if the neuron is in a hidden layer."
3589.78,3619.6,"And here, let's say, this Eij and how we should change the weights. I'm again just filling out the formulas. There is this special situation again. If we look at, let's say, this neuron that is like a constant. There's 1 times this. So again, we can fill in these values for Zi equal to 1. And then it simplifies to this. So that's just..."
3619.66,3649.58,"like a simpler case. So what have we now seen? We know that how to update the weight, assuming a learning, let's say, rate equal to L. If it is in the output layer, we need to update it using this expression. If it's in a hidden layer, we need to apply this in a hidden expression. And now to go back to your thing here, like it may be odd that we are, let's say, assuming that there is a K,"
3649.58,3674.27,"But every layer, let's say, only depends on the next layer. And for the next layer, we have already computed if we go backwards. That's the idea. So this is now, let's say, the single thing that I showed you in the beginning that shows you basically all the formulas. It fits on one page."
3674.27,3702.51,"But, of course, you also realize you are unable to apply it if you do not know what it means. That's why I had to walk you through this process. But I also hope that you appreciate that you really see, rather than that somebody just dumps some definitions on the screen without explaining how it works, that you appreciate that you now hopefully really understand how it works. To summarize, we are nudging weights."
3702.51,3732.66,"and we know in which way we need to nudge the weights to reduce the error. And we repeatedly do that. Some comments related to that, there is this parameter L, which is the learning rate. It's typically, it could be a constant, but you can also use a strategy to reduce it, let's say, over different rounds. So you first apply everything with a certain learning rate."
3732.66,3761.57,"and over time you make it smaller. That's like you're walking down the mountain, and in the beginning you're making very big steps because you're clear that you need to go to the valley, but then you're almost at the valley, but you do not know really what the lowest point is, and then you start taking smaller steps. That's a possible strategy. And I hope that you can see when we were talking about regression and SVMs that there were similar things."
3761.57,3791.31,"that were used there. So far, all my formulas were just devoted to a single instance. We are updating the weights based on a single instance. And you could repeatedly do that. That is called instance update. And that means that you look at one instance at a time, change the weights a bit, et cetera, et cetera."
3791.34,3821.65,"Another thing is that you do this in batches, so you do not update the weights for every individual instance, but you update it for the whole data set, or you partition the data set in batches, and then update it like this. One epoch, that's a term that is often being used, that means that you have made one round in such a way that you have used all the instances once to update the weight."
3821.65,3848.88,"So one epoch could be just a single update where you update the weights based on all the instances in one step, or one epoch could be as many steps as the number of instances that you have, right? Because you do it for every instance, let's say individual. So both strategies can work, and people typically use something in the middle, right, where they determine this batch size."
3849.17,3880.75,"From a theoretical point of view, only batch updating guarantees that you reach a global minimum. Note that there could be this, like with instance updating, that goes much faster. You look at one instance and you update the neural network, rather than computing everything for a million instances and then doing an update. So this may be faster."
3880.75,3909.58,"but it's also a bit unpredictable because different instances may lead, let's say, the weights in different directions. So if you want to have strong guarantees that you're reaching a global minimum, then you need to do the updates for the whole data set as well. And experience shows that typically something in the middle is something that works better, that you do not have this kind of seemingly random behavior."
3909.58,3940.18,"That you have something like this, but that goes faster. So how can this work? So before we were basically just considering this situation. So how can we do this situation? And that is due to the sum rule. So the error of a batch is the sum of all the errors over the different instances. This was the error for a particular instance."
3940.18,3970.64,"So I can simply rewrite this into this term. We are now interested in how should we nudge the weights not for one particular instance, but for the whole. Our goal is to minimize the error not for one instance, but for all instances together. And they may be conflicting, right? But we want to minimize the overall error, which is simply the sum."
3970.64,3999.58,"And because it's simply the sum, right, the derivative of the sum of something is simply the sum of the derivatives, right? So that's why you can compute this in an easy way, right? So the way that it would work is that you apply the neural network to all the instances, you get errors for all of them, and using that you update the weights, right? That is the way to go."
3999.58,4025.63,"Then when to stop, you hopefully reach a situation where the derivatives are equal to zero, but convergence can take a long time. So there are different strategies to stop. And it may be that you need to consider your data hundreds or thousands of times. This makes this an extremely expensive process. And that's why you see..."
4025.63,4068.69,"At the moment that you're dealing with neural networks, you typically need to have lots of hardware to be able to do this in a meaningful way. Clear so far? You can do that. If you look in certain textbooks, they will actually do that. But there is no difference because whether you are trying to reduce the sum or the average, it's exactly the same thing. So you can divide it by the number of instances."
4068.69,4107.39,"But reducing the average error or reducing the sum of all errors is exactly the same question. That's why I did not put it here. Any other questions? This is an example taken from the book because I constantly want to relate things. No, because we are looking at, let's say, derivatives."
4107.39,4131.38,"So we are not looking at some absolute value. We just want to reduce it. And to reduce the average is exactly as reducing the sum. Because if you divide by n, n is a constant. And it does not have an effect on things. That's why the result will be exactly the same. There is no difference."
4132.08,4155.31,"This is an example from the book. It's not very elegant, but I want to relate, let's say, on some slides, the way that I explain it and the way that you will find it in this book. So note, there are, for example, other conventions. So we are using this convention W0. And then..."
4155.31,4183.97,"like for this constant one. Here they are drawing this explicit, let's say, neurons that have a value of one, which is the constant. And then, given this neural network with these particular weights, it is shown how this update works. But at the instruction, you will see, let's say, many more examples to play with that are a bit elegant. But let me try to walk you a bit through, let's say, this example. So..."
4183.97,4212.54,"These are, let's say, our initial weights. Just think of them as random. What we know is that this is our input. I believe that our target output, given these inputs, is equal to 1. Our target feature is 1. We want 1 to come out, and this goes in. We have these initial weights. You can think of them as random."
4212.54,4242.16,"And now we can do, let's say, feed forward. So for example, x is equal to 1, x2 is equal to 0, x3 is equal to 1. So I just, let's say, fill in the formulas. For example, for neuron 5, we have 1 times minus 0, 3. We have 0 times 0, 1. We have 1 times 0, 2."
4242.16,4272.35,"And we have 0, 2 times 1. That's exactly this expression. So the weighted sum that goes into 5 is equal to 0.1. Right? Now we apply the sigmoid function to this. So A5, what goes in, is equal to 0.1. We apply the sigmoid function. And what comes out of this is 0.525. Right? Now I go to the next layer. And I'm not showing you the whole network."
4272.35,4301.95,"I assume that Z4 is given. But what you should note here is that if I compute what goes in here, it is this 1 times 0,1. That's the expression that you see here. And here we have minus 0.2 times this Z5 value. That's what you see here. And we also, it's not shown here, but this Z4 was equal to 0.332."
4301.95,4331.58,"It's not shown. So again, we look at what goes in. It's this value, the weighted sum. Then again, we apply Z, and this comes out. So this was the neural network outputs 0.474. That's the output. And let's assume that the target feature is equal to 1. So what is the error?"
4331.58,4369.65,"The error is equal to, let's say, what comes out here, Z6. That was this value. And the target feature is 1. So that's equal to this expression. So the way to visualize it, when you apply the neural network, when you apply it, you try to make a prediction. You start from the inputs and you go to the output. Layer by layer. That's feed forward."
4369.65,4399.12,"And backpropagation is then at the end an error comes out. And then you look at the error. And then you kind of go backwards to the beginning, updating all the different weights. So that's why if we apply it, we go forward. We know what the error is. The moment that we know what the error is, we know how to update the different weights. That's the way that works. So here with feedforward, although I just show a part of it, we basically go from here to this output."
4399.12,4427.98,"0.47. And here, in the backpropagation, we go from this error, 1 minus 0.4, et cetera, and we go in this direction. And now, here you see the formula that I showed you before, right? That is on this slide, right? That tells you how to compute E6, right?"
4427.98,4457.89,"And that is equal to this expression. And that gives us that E6 is equal to this expression. And then using, again, this other formula, so we know that this is equal to that, right? It's also on this slide. Then we know that to compute this one, we need to do this. And the moment that we know this, we know in which direction to change it."
4457.89,4484.03,"And we multiply that with this learning rate parameter. And the moment that we do that, this is the value that we come to add. And of course, this is incredibly painful to do this by hand, right? It's very confusing. But it's basically just applying the formulas. And I hope that you now have an intuition on how this works. So what you should be able to expect is that, I don't know, also..."
4484.03,4513.74,"at the exam, for example, that you get like a partial filled out neural network that has already undergone some training. And then you get a new instance and you simply have to say how to update the weight. And like this is quite painful to do that. So typically like part of the solution is already given just as I did it here. Yeah, so in the previous slide, I showed you how to update this weight."
4514.16,4542.46,"And then once I know this value, I can now also compute E5, then I also know how to update this weight. And that's how we go, let's say, backwards. And this is in the end, let's say, the change. So this was the old weight was 0.2. And after the update, it is 0.194. This is how we can update all the different weights. Yeah?"
4542.46,4572.58,"This is, let's say, some screenshots from the book. And again here, this is this slide with all the formulas that I indicated before. Okay, let's look at, let's say, some things that you will also, let's say, see in the future. Right, there are many different types of neural networks that we can talk about. We talked about convolutional neural networks in the last lecture for images."
4572.58,4601.87,"There are, let's say, LSDM networks that are for sequences. There are all these architectures that try to capture specific things. We will not go deep into this. We will talk a bit about transformers, but we will not go very deep into these things because, as it says here, it's loss of engineering, right? It's not one thing. It's a combination of many different things, which is very difficult."
4601.87,4631.86,"That's it to explain, let's say, in a conceptual way. One of the things that we will talk about in detail, and which is also very interesting for you to understand as a concept, is something that is called an autoencoder. And here it is very, let's say, interesting that you give it an autoencoder in input, and you basically want it to reproduce the output."
4631.92,4662.03,"And then you think, how could that be useful, right? So I feed it, I don't know, with an image, and the only thing that I want is that the same image comes out. Why could that be useful? This is useful if you deliberately push it through like a keyhole where you have a very compact representation of this bigger vector. So think, for example, of documents."
4662.03,4691.25,"You can describe a document by a vector that simply counts how often a word appears. And if you look at, I don't know, the English language, there are 800,000 different words. So that means that you have a vector of 800,000, right? And you can imagine if you start training this in a naive way, right? We have seen, let's say, how many training examples that you would need. This would never work."
4691.63,4720.56,"So this way you reduce the number of dimensions. You basically compact an 800,000 dimensional vector, for example, in a 50 dimensional vector in such a way that you can work with it. I think very interesting. Another interesting, let's say, architecture where you can play with these things is that you use a generative adversarial network where you basically let..."
4720.56,4749.01,"You can think of it, you let different neural networks compete with each other. One is trying to create fakes, and the other one is trying to identify fakes. And if you, again, it's like a transformer, you set up an interesting training environment, where at first you think, why could this be useful? And then, let's say, very surprising things come out of that, because you can..."
4749.01,4776.29,"use that to generate art. You create a gun where the challenge is like one is trying to create fake art and the other one is trying to identify fake art and you let them compete and then after a while, if you set it up in the right way, you see original art that looks as if it has been made by people."
4776.29,4805.26,"So here you can see that with images. So none of these people that you see here exist. When I would have shown this slide, I don't know, in 2019, people were very surprised by this. Today with, I don't know, with JetGPT, et cetera, you know that these things are possible, right? And I hope that with the lecture today you get a bit of the idea of the mechanisms that are working behind this."
4805.65,4835.34,"Generative AI will be a topic that will not be very big in this lecture series, but something that I will talk about when talking about transformers and talk about text mining. I'll skip this. So one of the things, and I put it in here just as a pointer to a later lecture, one of the things that we will use for unsupervised learning are so-called self-organizing maps."
4835.7,4863.26,"And they also use this notion of a neuron. And I will not explain it now in detail. It's just like a forward reference of something that we will look at in the past. But the way that this picture kind of shows it is that you give it, let's say, lots of training examples. And the neurons are kind of folding around the data set that you have."
4863.26,4890.86,"As I said, I do not want to explain that now in detail. It is just a forward reference, but you get, let's say, these beautiful visualizations that capture, let's say, the characteristics of the data, right? Without telling it, like, this is the target feature, right? And, like, I think that that's an approach that is, again, something very different, creatively losing the ideas that I said before."
4891.82,4922.27,"So to summarize, this kind of concludes, let's say, the topic of neural networks. So it is very powerful. It is very flexible. It works very nicely. But it also has these drawbacks that I showed earlier. So the main drawback that you can take from today, if you have millions of weights, you need to have tens of millions of training examples for it to work."
4922.27,4951.28,"And this balance between overfitting and underfitting is always there. I also hope that you have an idea, like in the previous lecture I showed you these pictures with traffic lights, whether they were green or red. I hope now you also have an idea, we are in a parameter space, we have all of these different weights, and probably there is one weight that I change, and suddenly it swaps from red to green."
4951.28,4978.9,"for an unexplained reason. That's one of the challenges and that's why, I don't know, many people are working on explainable AI to try to better understand why it behaves in a particular way. So that's something that's very important. Some slides about overfitting. So it is easy to find patterns in data if you have many free variables."
4979.41,5006.82,"that you can set, and there is this famous quote of John van Neumann, the inventor of the computer, that with four parameters I can fit an elephant, and with five I can make it wiggle its trunk. Just think of it, you have a few dots, and there are many different lines that you can draw through these different dots. And if you opt for higher dimensional functions, it can be super weird."
5006.82,5035.02,"You can make it do everything. And that's something that you should bear in mind. So this week there is only one lecture. But as I said, which you can see here, so on Wednesday there is no lecture. There will be an instruction devoted to the neural network part. And also the assignment, I'm not sure, has it been posted already?"
5035.41,5053.07,"If not, it will be posted today or tomorrow. So then you can get started on it. Is everybody here in the room already in a group? I think so. If not, find somebody reliable. And see you next week. Thank you."
