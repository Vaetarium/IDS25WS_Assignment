start,end,text
1.74,29.87,"Okay, I suggest we start on time. We have a lot of kind of content to get through today. Welcome to the fourth lesson for IDS, which is about regression. And I will start with kind of the outline, what you will see today. We'll start first with the basic idea of regression. And then we will kind of look at it also with visualizations and explain."
29.87,57.87,"the kind of concepts and ideas that are behind the simple linear regression, then expanding it, looking at it also more formally with multiple descriptive features. Afterwards, we will briefly talk about how the results, like when you train a regression model, can be interpreted. And afterwards, in the second half of the lecture, we will handle categorical features, both as kind of inputs or descriptive features and target features, leading us to the topic of logistic regression."
57.87,87.81,"And at the very end, we will also briefly comment on two other extensions like modeling nonlinear dependencies in the data and multinomial regression task. As you see, I'm not Professor van der Aals. He is back next week for the lecture on SVMs. My name is Aaron. I'm one of the PhD students here and also the course coordinator for this year of IDS. Okay, let's get started with the basic idea of regression first. So regression is at least presented in this lecture as an error-based learning approach."
87.81,109.46,"What this means is that we start with an initial model, an initial linear function in the case of regression, and then kind of see how it performs based on some error metrics, and then iteratively try to kind of improve the function, lower the error, and then get, at the end, a well-adjusted model. So this is kind of what is visualized here."
109.46,130.34,place to start out initial linear function and initial model let's say randomly and then you improve it iteratively until you are like at the spot where the error let's say is minimized or is very close to being minimized and use a useful model in that sense so there are also other error-based learning approaches in this lecture so in the next lecture we will cover svms
130.34,154.48,and the lecture after that will cover neural networks which are also inherently error-based approaches but there are also more approaches which we will not cover in this course at all so for instance genetic algorithms where you have kind of a population and you mutate it somehow and then have a survival of the fittest approach where the best performing instances come to the next generation but in general I hope to
154.48,183.84,"The principle, which we will then see also in the example of linear regression in this lecture, becomes clear where you try to improve this randomly initialized function. So how does the regression model for a very simple case look? If we have a very, very simple case where we have just one descriptive features shown here as the x-axis and one kind of target feature, the thing you want to predict on the y-axis, this is just a line, right? A line mapping values from the one descriptive feature, the size, to a y-value, to the target feature."
183.84,215.15,"Here we have the size. This is the example we introduced later on. And the rental price is kind of the value we want to predict. And what we want to learn is a prediction model, so model mapping x values, so the size, to the target feature, the rental price. And we, of course, want to not find any such function but the one which kind of performs best, so the one that minimizes the error. If you remember from last lecture, we looked at decision trees. And there, what we did is we started out with categorical features."
215.15,244.38,"because all of our splits are always discrete. And then we showed you approaches of how this kind of idea can be extended to also continuous features. In regression, we work the other way around because at least the initial idea and the concept is based on continuous features. And then we will show you how you can also use categorical features both as input features or as descriptive features and also for the target feature for predict. And this is where the logistic regression then comes into play. But in general, both approaches, so decision trees,"
244.38,272.54,"and also regression supervised learning techniques because we have this target feature in our data. It's something that we have access to and we use also to predict and also to measure the error of our approach. Okay. With that out of the way, let's start with an actual example. So this is the example we saw before, but kind of really introduced here. So this is a data set with different columns, with different features. We have the size, the floor, the broadband rate."
272.54,300.61,the energy rating and the rental price so this is a data set of rental prices in of offices in dublin and what we can do is if you want to train the regression model based on that data let's say we pick the rental price as the feature we want to predict what is the thing we want to get out of the model and we use as descriptive feature to keep it simple first only the size so what we want is to find a model that predicts the rental price based on the size of the office and in that sense
300.61,329.71,"just to make sure everybody's on board, we take the rental price as the target feature, the thing we want to predict, and the size as the descriptive feature as the input for our model. And the question you would then answer with the regression is basically how does the rental price depend on the size of the office? So you would, for instance, assume probably if the office size is larger, like larger square meters, you would expect this price to also go up, right? That's maybe the intuition for this example data set. And with..."
329.71,358.4,"The simple case of linear regression, we always assume a linear dependency. So we assume that we have a function which predicts the rental price based on the size, and it's like a linear function like this where we have b, which is the y-intercept, so the line meets the y-axis, and a is kind of the slope of the function. It kind of specifies how the rental price increases if the size increases, right? I think that's hopefully clear. And you could then, to find a linear regression model, just choose any values for b and a, first of all."
358.4,384.77,"So we could say, okay, let's say 6.47 is B, and A is equal to 0.62. And we can do that, and you can then also use this model, plot it, and so on. But we, of course, need to know if it's a good model or not, and also we want to learn the best model that describes the data, that is the most close to our data that we have. But before we get into that, let's first look at the syntax of things."
384.77,414.16,"So if we look at things a little bit more formally, what we have is kind of this matrix. We have the target feature here in the first column, and then here M descriptive features in the other columns. And this is exactly how our table before also looked. We had the target feature here to the right, but we also had columns for all the descriptive features. And then each row of this kind of matrix corresponds to one instance of our data. And how we would write the prediction model here is then that we predict the target feature and our..."
414.16,441.78,kind of regression function is this model so this math bbm which takes as input the different values of the descriptive features so if you want to predict for instance this target feature t1 you would take all of these descriptive features as input and the things that we can tweak are the weights of the model so there was the a and b we saw in the previous slide and those in this notation here correspond to the weights of the model so this w0 to w
441.78,464.59,"And note that w0 is kind of a special case here because this is the y-intercept. This is something that's not multiplied with any of the descriptive features, but it's just the y-intercept, and it's multiplied by one, basically. So we will throw most of these things out for now, and then revisit them later. I will just introduce this notation so you are kind of familiar with it, and if you see this m or w, you don't get confused."
465.2,495.12,"So a very simple case linear regression. This is the data set we saw earlier, but now plotted. So on the x-axis we again have the descriptive feature, and on the y-axis the target feature we want to predict. And this is the function I showed you earlier, now also plotted to the data, and as you can see, it at least looks visually to be a very good fit. And to map that to the syntax we saw before, so what we predict is the rental price, this is the model prediction here, the y-intercept is this zero weight here, w0, and we have the slope of the function w1."
495.12,519.82,"times the value of the size of the descriptive feature d1. Hope that's clear. Should we run here? Okay, good. And, of course, this function we just plotted is not the only one we can plot. We can, for w0 and w1, just put in any values and we get different functions. So here we plotted a few of them where we kind of the w1 weight. They all have different slopes. And our..."
519.82,541.87,"Go is now in this kind of jungle of the different linear functions to pick the one that we like the best or that is the best fit to our data. And the intuition there is we want to pick the function with the smallest error with regards to our data. So with that we of course need to somehow introduce what we mean with an error and there are different definitions for that. In this lecture we mostly use the sum of squared errors, more on that later."
541.87,570.02,the formula looks kind of like this and what you do in general with all of these error metrics is that you go through your data set so each point here is kind of a value in our table and we look at how different the actual value the target value is compared to the predicted value for instance here if you listen kind of to our prediction model and plug in here this x value of size we'll predict this rental price but the actual rental price for this instance is a bit higher so this difference is kind of the error here what you do is then you
570.02,597.04,"sum up the error squares for each of these different instances, and then compute the sum of it, divide by one half. But there are different ways to do that, because we have different kind of notions of errors. So what I just described, we will take a look at an example in a moment, is the sum of squared errors. But we could also do the mean squared errors, the root of the mean squared error, and the mean absolute error. And of course, there are also more things you can define. But those are the most common ones."
597.65,623.09,"So let's take a look at an example. If you have the sum of squared errors, so the function I introduced earlier, and we have these four data points here, and this prediction model, so this is our regression line, the kind of error sum would be, okay, we take each of these differences, so here, this point is exactly on our line, so our error is kind of zero, and we say zero squared, then here we have an error of minus two, and we then square this value, zero."
623.09,652.46,"3 squared as well here. And then at the end, we divide by 2. The reason for this 2 will become clearer later. It's just, let's say, a nice property to have because the derivative of that then is even simpler than it would be otherwise. But you could, of course, also divide by a different value, let's say by n, because this is the mean, the scaled version of that. They do the same thing as before. So for each instance, you look at the error. You square it. You sum them up. But you divide by 4, so the number of instances, the number of points we have here instead of."
652.46,680.43,"just by 2. And then you get a different error value. What you can also do is to take the square root of that. This is maybe, if you listen to any statistics courses, the iteration between difference, variance, and standard deviation of a distribution, because with this we kind of handled the square factor here that we squared every error. But you could also just take the mean value, the mean value of the absolute error, so that you do not square the errors, but just take the absolute value."
680.94,709.18,"I think this is pretty clear. There are also more things that you can do, of course, but these are just a few examples. In this course, we mainly use the sum of squared errors, mainly because it has some nice properties if you talk about the derivative. And for others, here it's a bit more difficult. For instance, for maybe also intuitively, if you have something like the absolute function, so here, this can sometimes become tricky if you track the derivative or do some other properties of the function."
709.18,751.54,"So we will stick with the sum of squared errors mostly here, but you should also know that there exist other error types and also kind of know the idea behind them. Okay. So is anybody still on board? Is there any questions at this point? Yeah? Yeah, exactly. So for these examples, it also makes them easier to explain them to you, but we will get into derivatives in just a moment. So there you will also maybe see why these properties are important here. Yeah? Yeah, I mean the..."
751.54,781.97,"The question also always is, what is your goal for the model? So you should, at least in theory, always choose the error function such that it also accurately measures the error that you have in mind, so the performance of the model. If you are, for instance, interested in the maximum error that is in your prediction model at all, this would also be something that might be relevant to you in a specific use case. So definitely, for different domains and different applications, it makes sense to consider different error functions. Any other questions?"
782.03,807.98,"If not, we will sadly have to get into derivatives. So this is just a little refresher. I think most of the things on the slide you already know. This is also to make you a bit more familiar with the syntax again. So if you take the derivative with regards to x of just some constant alpha, the derivative is 0, but it just goes away. I hope that's easy to you. If you have a function like this, alpha times..."
807.98,838.11,"x to the power of n, what happens is that n kind of goes in front and you reduce n by 1 in the exponent. This is the typical polynomial case, I think you also know that. And in general, if you have different functions which are kind of independent, let's say, and you take the derivative with regards to x, you can just sum up the derivatives. You can consider them separately. And also the last thing here on the left side is that if you multiply some function in general with a constant, you can also factor that constant out and take the derivative of the function."
838.11,863.86,"like inside and then multiplied with the constant. I hope that's not too scary. Now let's get to the chain rule. So many of you probably also know the chain rule from school. So the chain rule is applicable if you have kind of nested functions. We have an inner function, in this example g of x, and an outer function f of g of x. And if you have that, we can kind of use this trick to build a derivative. And what we do is we take the derivative of the outer function first."
863.86,890.69,"also considering that inside the argument is g of x, and then we multiply that with the derivative of the inner function. Let's look at an example. So if you have this function here, x squared plus 1 in brackets to the power of 2, we have this setup, that we have an outer function, the outer function here, so the f is just a square function, mapping whatever is inside to its square, and the inner function is x squared plus 1. And if we do the derivative, just like..."
890.69,920.32,"by this definition here, what we do is, let's start actually on the right-hand side, we take the derivative of the inner function, so x squared plus one, and that's pretty easy, right, it's just two x, the one goes away, two here in front, and so on, and then we multiply that with the derivative of the outer function, taking also into account its argument. So here, derivative of the outer function, this is just a square function, so kind of x squared goes to two x, so it's two times, and you multiply the argument that was put in, so in this case,"
920.32,950.42,"What was inside is x squared plus 1, so this is 2 times x squared plus 1, and then what we said before, times 2x. And this is the final result you get. Can you follow along? Is that clear? Okay, good, because we will need that in just a moment. Also, to get you a little bit of intuition again, also just a refresher, if you have this function from before, so f of x, it's drawn here in the solid black line, and we also draw the derivative of that in this dashed line, we see that, okay, if the derivative is negative,"
950.58,980.24,"and we go to the positive direction, we increase our x slightly, the function value goes down. That's, I think, pretty intuitive. And also one other way around if the derivative is positive and we increase x slightly, the function value goes up. What you also have to keep in mind is that this always considers kind of the positive x direction. So if you are here and you decrease x, you actually get a lower function value in this direction. This will become later in just a moment because this idea of the derivative is what we use to do the steps."
980.24,1008.02,"to decrease the error. So the last thing I promised for the math background is the partial derivative. We will need that as well. So if you have a function which not only depends on x but also on the second variable, let's say y, we can build a partial derivative of that. Let's say we have this function here and we can then take the partial derivative of this function with regards to x and also with regards to y. So let's start with x. If you take the partial derivative of this function here"
1008.02,1037.54,with regards to x what happens is that you consider the y in the function definition to be just another constant so just like any other number you would treat it what this then means in practice is that this derivative for instance here is 2x and then you have minus y squared and the y squared just goes away because it's just like any other number the square doesn't matter here it's still just a number constant and it goes to zero basically so this is the derivative then if you only consider x as a variable the partial derivative if you consider y as a as a as a variable
1037.54,1068.48,"but treat x as a constant is then this, so here the same thing kind of applies, minus y squared goes to minus 2y, this x squared here goes away and so on. Good? Clear? Okay, great. Having done kind of this preliminary work, we can now first maybe visualize it. So if you have the function from before here and then you plot the derivative, the partial derivative with regards to x and the partial derivative with regards to y, you get these plots here."
1068.48,1097.7,"So here, this axis is the x-axis. I think it's probably hard to see, maybe. Here we have the y-axis. And on the z-axis, so the height of the function is what value comes out. So here of the function, here of the derivatives. And the color also indicates the z-value, because it's easier to see. And maybe just plugging some values in, if you go to the 0, 0 point here and look at what happens. If you increase x, you would intuitively see, so if you go in that direction,"
1097.7,1127.89,"that derivative there has to be somehow positive. And if you go here, you can also maybe slightly see that the derivative with regards to x in that point is also positive. So this also makes sense. So if we increase x here, we go up in our function. So the same intuition applies as with typical, let's say, two-dimensional functions here as well. With that background, we can now do what we do all of this for. And this is being the partial derivative of the error function."
1127.89,1154.3,"What we do is we build a partial derivative, this is the error function we saw before, and we build a partial derivative with regards to wj. So with regards to the kind of weight, the slope of the descriptive feature j. And the intuition maybe at a later point is then if we have the partial derivative with regards to this weight, because the weights are the things we can tweak, we can somehow tweak the weights using this derivative to lower our error."
1154.3,1180.74,the function value here right is the error so if you for example see that the derivative in a certain point is is negative we know that increasing this weight would lead a lower error right okay so let's do that um i also as a helper maybe gave you the definition of the model function here again and consider also this this is the general case where we have m descriptive features so not just one but m
1180.74,1210.42,"And if you take the partial derivative of the model function in general with regards to one of these ways, wj, the only thing you're left with is dj, so the feature value, because all the other things here, if you remember partial derivatives, just go to zero, right? So these are just constant, this is just constant, the only thing that's not constant is kind of dj, and it's multiplied with this, sorry, this wj, and it's multiplied by this dj as like a factor, so we remain with the factor in the derivative. Okay."
1210.42,1238.58,and what we can do to actually build the derivative of this error function here is to apply the chain rule again so we have this outer function which is again the square function here and we have the inner function which is ti minus mw di so let's do that and the the first thing you get is okay we had this before this is just two times with whatever is inside right so two times whatever is inside is here and we multiply that with the derivative of the inner function and the inner function
1238.58,1272.77,"Here is ti minus mw di. And if we remember, okay, ti is just a constant, goes to zero, but we are left with minus the derivative, partial derivative of that function here, and the result is dj. I just explained it before. So we have this factor minus dj here. We can then also simplify this and get this final result for the derivative of the error function. And remember, this is the derivative of the error function when tweaking the weights of the j descriptive feature. Okay, any questions? Okay."
1272.77,1310.29,"Yeah? Yeah, of course. So what is important to note is that we do not build like a general derivative, but the partial derivative with regards to wj. And what this means here is that you really only consider wj as being kind of the normal x in like regular function, let's say. So that is just a constant, like say 5 plus 2 times 10 and so on, plus, and then finally you get x times the constant dj. And all other things are also..."
1310.29,1358.0,"going away because they're also just constant. The only thing that's really dependent on your function variable, kind of your x in the usual example, is dj. Did it help? Yeah. So can you repeat? So here you mean this one? W0. Yeah, so W0 is kind of the special case because this is the y-intercept of the function. It's not multiplied with any other descriptive feature. Does this explain things? So we can, of course, also tweak"
1358.0,1395.44,"W0, and there you would kind of assume that this here is just one. Yeah? I don't know that term, but maybe, yeah. So it's the... Okay, yeah. Yeah, thank you. Okay. I hope that's at least clear to most of you. You can, of course, also take a moment, maybe at home, to revisit it and try to build a derivative, maybe, yourself for..."
1395.44,1429.22,"Maybe not the general case, but let's say for one or two descriptive features. Yeah? So the y-intercept. So basically, yeah, where your kind of function line, at least in the traditional sense, meets the y-axis. I mean, it's a bit harder maybe to talk about this if you have multiple descriptive features. But in general, it's always the thing that if you put all the descriptive feature values to 0, this is the thing you're left up with. So in that sense, it's always"
1429.22,1460.35,"of the y-intercept in the sense that the initial value, let's say, of the target feature you predict. Yeah, yeah. OK. So coming back to what we saw before, the different, let's say, function candidates and the performance of them. So here we have, again, the different functions. We have our data plotted. And intuitively, as I said before, OK, this one looks to be maybe the best fit. And this is also what we get if we compute the sum of squared errors. So this one has the lowest error here."
1460.35,1485.02,"And this would be the one we want to learn at the end. OK. So what we can do now, with keeping this derivative in mind, is that we can plot the value of our error function in regards to the different weights of our function. So here we have w0, so the intercept, and w1. And here this z-axis then corresponds to the sum of squared errors."
1485.02,1513.14,"when you pick these values and measure the error on your data set. So each point here, like if you imagine it, corresponds to a different line from our example before because it has different w1 and w0 kind of weights. And where we want to be, of course, is here at the bottom because the error is minimized there. So here you wouldn't have a very good linear function. It would not really describe the data well. But down here is really kind of the sweet spot. So how do we get there?"
1513.49,1531.02,"I mean, one approach maybe you could think of initially is brute force. We just try out different values and stick with them that have the best, the lowest error. But it's not really feasible, especially if you have multiple descriptive features. So we need a better approach. But fortunately, we have..."
1531.02,1557.62,"also keeping these partial derivatives in mind again, a nice property of our function space here. So it kind of looks very smooth. I think you would agree. And what this means we will see in a moment. But this makes it kind of easier. We have a different approach to find the minimum in that case. So maybe intuitively, also what you know from school probably, is that if you have a derivative of a function, you set it equal to 0, you can find this global and local minima and maxima."
1557.62,1587.62,"this feature of space, let's say this function space, has some nice properties that will mean that we will always find a global minimum indeed. And the idea with that is that the space is convex. Professor Van Aalz usually here goes on a small journey to the Dolomites, like a mountain region. I also was there as a child hiking, so I can kind of relate at least. And the idea is if you are in the mountains and you go down, you eventually reach the lowest point you can see. But in the mountains, the problem is kind of that"
1587.62,1616.88,different mountain groups and you will not necessarily at least reach the lowest point at all but you just reach like let's say local minimum but not the global minimum where your car is parked let's say because you have different kind of hill groups which have local minima but these are not always global ones so what you have basically in the mountain range is something like that so here we have a hill a mountain and we if you start here you would go here but actually the lowest point is here
1617.07,1643.18,"And the feature space of our error function, kind of in contrast to the dolomites, is that it's convex. And this means that if we connect two points, they do not intercept the line at any point, at any, let's say, other point. So this is not convex, this is convex. And the kind of result of that is that in the convex space, we always have a global minimum, at least for our functions here. And in general, this, of course, is not whole. This does not whole. We have also sometimes local minimum, which kind of make things more difficult because..."
1643.18,1670.26,"So I think what I discussed before, if you want to go down from a mountain, you could get stuck here, right? If you always go down, you would get here in the local minimum, but you would still not be anywhere near your car. And in the case where there's only a global minimum, if this space is convex, you have this scenario here that you always reach the global minimum if you always go down. So this is what is called gradient descent, because you have the idea that you always walk down, you descend down the mountain range."
1670.26,1696.08,let's hope not at a very high speed because the speed is actually the thing we can vary here so we know in which direction we need to go always down right we want to reduce the error but what is kind of unknown is how far you go because this just gives you a direction and you could maybe lower the ways a little bit but you could also have a larger step size and this kind of a design decision so kind of problems that could be if it's too big you overshoot so you start here
1696.53,1726.24,you take a very large step and you kind of on the other side of your mountain range again and you need to go back and back and forth and finally you maybe end up in the minimum but you overshot before and also just a small comment here in general if you have a too large step size it could also be that you do not converge at all but diverge because you basically ping pong back and forth on the other hand if it's too small what could happen is that you need a lot of lot of steps to finally reach the minimum and this is also of course annoying because it
1726.24,1755.89,at the end needs more computations and more time to pass so what is done in practice at least is that you start with a larger step size and then somehow get close to the minimum and at the end you are more precise and choose a smaller step size so the step size at least usually decreases over time in your gradient descent approach okay so let's do that for one of the examples this is the error surface we saw before and let's say we start with a randomly generated parameter function so here we have just
1755.89,1786.83,"Maybe this is a function we saw initially, but it's probably worse because the error here is quite high. So we have just one function, and then we do exactly what we did before. We step down in the error space. So we reduce the error by tweaking our function rate, so w0 and w1. This is the same visualization just in 2D. So here, a darker color means a lower value. And we start here, and then we gradually do steps, always decreasing our error based on tweaking the rates of w0 and w1. And at the end, we reach this."
1786.83,1813.78,same global minimum no matter where you start because you always go down and you know in this convex space you have this one global minimum and we can have another example so this was the rental price for the offices and there you also have these parameters so w0 and w1 and you start somewhere you do steps down tweaking so here for instance i think this w1 so you would first
1813.78,1838.42,let's say it looks like it decreases the the slope so this value here of the function and then at the end the right is also updated maybe also the whole time but but like smaller smaller changes apply and at the end you arrive at this minimum function where the error is minimized you have your best trained perimeter so the rates of the functions are clear now um yeah and remember in each of these steps
1838.42,1865.79,"what you have of these points here, you have actually a fully defined prediction function, right? It just doesn't perform as well as the one in the final step. So if you do this on the data set, we would get this. So we have this initial line here, let's say, which is a bit far off from our data. And we gradually improve it, gradient descent, step, step, step, until it's a very good match for our data. So this is also the evolution of error, where it increases rapidly at the beginning because you kind of get very"
1865.79,1907.12,"close to the better function. And at the end, it kind of stays stable, and there are not that large improvements anymore. Yeah? Yeah. Yeah. I mean, what kind of speaks against it is that I think maybe it's just very small changes here, because you can kind of see that it doesn't terminate here, but still, and it looks like it goes only in that direction, let's say, at the end. And you would also expect at least that once you"
1907.18,1935.92,"once you fix like the w1 parameter that there would be at least one value for w0 that kind of is the best performing. But I agree it kind of looks very flat here, so maybe the slope is just very small. Okay, any questions regarding the initial gradient descent approach? In a moment we will also look at the pseudo code definition of that. If not, let's..."
1936.21,1964.5,continue with multiple descriptive features so for the visualization and so on we always just stick to one because it's just easier to see but in general you can of course also consider m descriptive features and almost nothing changes right so this is just some notation here so let's say we have this m descriptive features we can also build them as the sum here from j equal to one a equal one to m and here's one trick which makes it very easy to write this compactly
1964.5,1994.08,"And this is also maybe related to what we said before. If we consider there to be like a mock descriptive feature, which is always equal to 1. So this is kind of the d0 here, and it's always constant run. You can write this very compactly, because the w0 is kind of the only exception here, which is not multiplied by a d value, by the descriptive feature value. And to make it just for notation, let's say, easier, we can just say, OK, we've just defined d0 to always be 1. Then you can write this as a very compact dot product of like 2."
1994.08,2022.11,"vectors or matrices depending on if you consider all features. But this is just like notation-wise, nothing changes apart from that. But it's just easy to write it like this. And we just compare these two lines. It's very compact. But other than that, nothing changes with multiple descriptive features. So our error function looks like this. So here we just plug in the dodge block we saw before. But we already did the derivative of this."
2022.11,2049.81,error function in the general case for m-descriptive features before so there really nothing changes its business as usual you can do the same thing you just have let's say multiple rates that you update right and not just w0 w1 but also the other ones so if we do that for our data set what we get is maybe this that we want to consider additionally now the floor number the broadband range and the rental price so here we exclude the energy rating more on categorical features in a moment and with that we can have
2049.81,2083.09,"then multiple weights, so this W0, W1 again, just as before, but now we also add W2 times the floor size and W3 times the broadband weight. And then we can do the same business as usual. We train weights for these different parameters. Then let's say we get this function as the best approximation of our data. Then let's look at how it looks like from an algorithmic standpoint, but this is just maybe a repetition of what we saw before."
2083.09,2109.78,"So we, in the first step, randomly choose a starting point. So we choose values for our weights, define an initial function. And then from there on, we repeat these different steps until we get a good function. And what we do in each of these repetitions is that for each of the descriptive features, we update the weight that is defined by our function here. So wj is updated for the descriptive feature j, depending on the error delta. So this is where the derivative comes into play."
2110.22,2140.16,"And this is exactly here with the speed of a, so alpha is the step size and error delta is kind of the direction we need to go in. And at the end, until convergence occurs just means we have some stopping criteria. Commonly when improvements become too small, also maybe the changes that you do to your rates become too small, but you can of course define different criteria. But I think in general it's clear that you can somehow at least at some point say, okay, that's good enough. You don't always need to go to the optimum, but can also stop a little bit earlier maybe if it's..."
2140.16,2170.74,pleasant for you. The only thing that's really maybe tricky or that you have to be careful here is the updating of the weights because here maybe you have an intuition for why we have this error delta from before and if you look at the actual value so this was the derivative of the error function but we can see now it's kind of added so remember there was a minus in front of it it's also here in the top right but this minus disappeared we just said alpha the step size times the error delta here.
2173.1,2205.31,"Does anyone have any intuition of why we lose this minus here? I think what you're saying is right, but you have a positive derivative. If you increase the weight, let's say..."
2205.31,2233.81,"wj and the derivative is positive, what happens is the error, so the function value increases. And this is, of course, not what you want. You want to decrease the error. So in the case that the derivative is, let's say, positive, you want to go in the other direction, the negative right direction. So this is where we basically subtract the derivative here, because we always want to go in the other direction, then what would increase the error. And here, then, the case, so if the derivative is positive, we need to lower the weight, go in the other direction. That's clear. OK."
2234.03,2278.86,"Any questions regarding the algorithm, maybe also the error function, the derivatives? Yeah? The step size? Yeah, so this is just a very simple pseudocode, but in practice what is at least commonly done is to start with a larger one and then reduce it. There are also different functions you could do, like maybe half it in every iteration, but this kind of depends on your use case. Yeah?"
2278.86,2305.23,"At least in practice, we subtract this derivative value. So the minus then cancels each other out. If minus, minus this, then this is what I mean with fluid. So what we do is we subtract the derivative in that sense. OK. If there are no more questions, let's talk about how we can interpret this result. So let's say we have this"
2306.32,2333.78,"Okay, so let's say we have this train model and for one distributed feature it was kind of easy to see. So here if you just have the size as an impact factor, we can see, okay, if this is 0.62, let's say we trade a new function and there it's 0.1.6 or something, we know the size now has a larger impact on the value of the rental price. In that case, it's very simple. But what if you have multiple features? Let's say we have the size, the flow, and the broadband rate again."
2333.78,2358.59,"And we have these different weights here. So could you say that the floor is less important than the size, or has a negative effect? What about the broadband range? It's very low value. So could you say, in this instance, that the broadband range has a lower impact on the model than the size? I'm not going to go into that trap, because the answer is no. And the intuition behind it is they could be scaled very differently. And there could be different units. For instance, the"
2358.59,2381.57,"Square footage, let's say the size of the apartment could be in square centimeters, in square meters, and so on. The broadband rate could be in different units, and the price of the rental price, the target feature, could of course also be in different units, so in euros, dollars, pounds, bitcoin, or thousands of euros. And in general, with that in mind, it's very hard to interpret these factors, the different rate factors."
2381.57,2410.29,"Of course, you could say, okay, I scaled my data before, but even that has some problems because the impact that the model learns might not be directly scaled as the data you scaled. But what can you do instead? So that's kind of not a very good answer we have for you, but what you can do is a significance test. So we will shortly describe how it works in general, but more details on that can be found either in the book we use or in the last few slides, which will not come in the lecture in life, but you can look and read them yourself if you are interested."
2410.29,2438.7,"So the idea is that we first create a regression model using all of our descriptive features, and then we create other regression models, always leaving one of them out. And with that, your intuition would also be, okay, if the feature is important and we leave it out, the performance kind of drops heavily, so the error would be much larger than before. So this example we do, so we create k different regression models if we have k different descriptive features that we want to test out, and the difference of the error kind of indicates how significant the feature contributed."
2439.28,2468.75,"And in the hypothesis test, you would then define the null hypothesis, so there you would say, okay, the feature does not have a significant effect on the model, and you would then try to look if the null hypothesis is rejected, and if it's rejected, you would kind of say, okay, this does not hold, so it does have a significant impact. If you do that for our descriptive feature from the example before, size, floor, and broadband rate, you would see that we have these rates here, we saw them before, but the p-value for size is very, very low, so..."
2468.75,2495.23,"very low our threshold here, the floor has a very high p-value and broadband rate as well. And what this then intuitively means is, okay, for the size we reject this null hypothesis, so we assume that it has a significant effect, but for other ones we can kind of ignore them, throw them out, also of course to make our model simpler again, because they do not really have a significant effect on the performance of the model. It is just maybe to give you at least some"
2495.23,2526.06,"some option or give you some ideas of how you could still interpret the results of a regression model if you cannot consider the rates themselves. So that was the first part of the lecture where we talked about, let's say, normal linear regression. And next we will talk about how you can handle categorical features. So this is basically corresponding also to the second part of the last lecture for decision trees where you did the other way around. Now let's look at how we can include categorical features."
2526.06,2555.31,"include categorical descriptive features, so as input, and you can also predict categorical target features, so classification, so as the output. And we will start first with the categorical descriptive features. So this is also maybe the example we saw before. We had this table with the office prices and we have this broadband rate, which was a number, but we have also the energy rating, which was just A, B, and C, like this here. We have discrete values."
2555.6,2587.04,"And one easy way that you can handle this discreteness is just the one-head encoding. And for this example, it means that you include new features instead of the original one. So energy rating A, energy rating B, and energy rating C. And the idea is, OK, if you have a C value before, you put a one in there for the energy rating C feature. So you could, of course, also do this if you have more descriptive features. And this is a very general report, because at least in view, you can always do that."
2587.04,2612.66,"In practice, there are some problems, we will see that in a moment. But what are other options? So if you have just a binary value, so yes or no, or faulty or not faulty, you can of course also include it just as one binary number, so zero or one. But then you don't need to introduce two different descriptive features. If it's a categorical variable and it's ordered, you can also at least try to give it a numeric value. So let's say if you have..."
2612.66,2642.8,"something like grades or rating, you would have excellent as 1.0, good as 0.7, poor as 0.3, and so on. Of course, there are also some, again, maybe difficulties because the linear regression model does not know about the scale you have set up, and if you have features which are not kind of this clearly ordered, you, of course, can't really work with that approach because it gives kind of bogus results. So the issues we have is first that if you do not have an ordered categorical"
2642.8,2668.27,"variable, so very simple encoding, just let's say the names of cities or of countries, you can't really also give it an order, so it doesn't really make sense to do that. Also, if the regression model doesn't really know about your scale and your discreteness, so it doesn't know that there's only 0.3 and 0.7, but it can imagine any value in between, and also the model at the end does not encode this information somehow."
2668.46,2691.5,"Moreover, in one-hand encoding you also have these dependencies now between different features. So you know if the energy label A is 0, energy label B is 1, you also know the energy label C must be 0 as well. But at least in the linear sense and in the function, it would also allow you to plug in 0.66 and A equal to 1. It doesn't encode and doesn't compress this information somehow."
2691.5,2721.5,"What is also a problem in practice, at least, is if you have a lot of different possible values, let's say country name, city names, doing one-hand encoding is very overcrowded. It introduces a very large feature set of new features, which makes it also computationally expensive and even infeasible in often scenarios. So there you have to find some other approaches, but at least the simple cases to just do one-hand encoding, maybe some of the ordnance stuff applies as well if you have such a feature."
2721.5,2761.3,"is at least some of the options you have for handling categorical descriptive features. And next, we will cover categorical target features. So the thing that you want to predict is now discrete and categorical. And let's say we have this dataset here. So here we have as the descriptive features, we again say we have continuous features. So x and y are continuous, just to make things simpler. But of course, you could apply one of the techniques we saw before, one-hand encoding or something like that, if you do not have these properties."
2761.3,2785.54,"But now our class label, the thing that we want to predict, the target feature, is discrete. It has this binary class of plus or minuses. And at least for the first part of this categorical target feature slides, we also only consider binary decisions, so true or false. And maybe the first idea you have if you want to somehow apply the regression model at all is that you can"
2785.54,2812.05,"Regression gives us a line, so we can use it maybe as a separating line between the instances. If you plot them here on the x and y-axis, you then have the different instances, let's say here, plus and minuses, and you can find a line, a regression line, let's say that nicely segments them. So here we only have the pluses, and here we only have the minuses. And what's very important here, now the value of our line is not that important anymore, so it doesn't really give us a..."
2812.05,2840.26,"for one combination of x and y value, we plug in, but it gives us kind of this decision boundary. So if you classify it as a plus or minus. One example from this lecture is then, let's say we have on the x-axis the glasses of beer, a person drinks per week, and on the y-axis the number of cigarettes they smoke per week, and the pluses then corresponding to that person at the instance dying before an age of 50. So there we would maybe intuitively at least expect that there are many pluses here."
2840.26,2871.1,"at the top above the line and relatively few below the line. And this line is then defined in our usual regression sense as w times d, so the weights of the functions times the weights of the descriptive features. And the line is then plotted here where it's equal to 0. So this is kind of our decision boundary where it's equal to 0. Then you can maybe intuitively think, OK, if it's above 0, this means something. Maybe it's above or below the line. And if it's below 0, this also means it's above or below the line. So let's look at an example."
2871.1,2900.14,"just some weights here, so w0 is 60, and we have those weights for w1 and w2. We would have this line here again, and then we could look at instances, so let's say 10, 10 here, and we could see, okay, if we plug these values into our function, what do we get? We get 10, so a positive value. In this case, this then corresponds to that the instances here below, or the feature space here below, always has a positive value of plug-in. So positive means here below the line,"
2900.14,2929.12,"and here the negative, so if you plug in 30, 20, we get minus 60, so a negative value. This means that these values are above the line, kind of. But what's very important to note, and kind of also confusing here, is that this direction is not really inherently, right? This function we define, sorry, which we said equal to zero, is just that, and we can, for instance, multiply it by minus one. And the line we draw here stays exactly the same, right? It's zero exactly in the same spots, but..."
2929.12,2951.95,"everything flips. Because then if we have, let's say here this minus 1 multiplication, we have this rate minus 60 instead of 60 from before, 2 instead of minus 2, and 3 instead of minus 3. If we now plug in our values, let's say 10, 10 from before, we get minus 10. So now minus corresponds to values below the line. And plus, so 60 above 0, corresponds to values above the line."
2952.08,2989.41,"So there you just have to be careful and have to always see how it's defined in your instance, in your case, and for the line you look at, because there's no general rule. And also in the literature, and also in examples, in lecture material, it can be both ways. So just be careful there. So now, yeah? It's not, yeah. So it's not, I mean, the thing to do, at least in practice, is you can plug in values, like what we just did before. If you had this 10, 10."
2989.41,3028.14,"We just plug it in and see if it's below or above zero, and this then means that all of them, because this is a line where it's zero, have to be below or above zero, so they have to be the same. From the function, at least, it's, I think, not that easy to see. So what I would suggest is at least just plug in values. You also need to plug in only one value, right? Because then you know what is below the line, and you can know the opposite is above the line."
3028.78,3058.8,"Yeah, of course. This has to be somehow given to you. And what we do right now is actually we give them also values. So also we make values 1 and 0. So we say minus here is 1 and plus is 0. And we then do exactly what you just mentioned. So then we somehow need to map this prediction to this decision boundary. So if you know here below the line, let's say we want to predict 1 because we see a lot of minuses there, we would then say, OK, if this value,"
3058.8,3092.29,"Here is above 0. Again, with this function we have in mind here, we plot it here. Above 0 means it's here below the line. Just watch out there. And value below 0 means it's above the line. So if it's above 0, so below the line, we predict 1, so minus class. And above the line, we predict 0, the plus class. Because one thing to note also is that in our model, we want to predict something discrete now as well. We can't just get the value of w times d and use that somehow, because"
3092.29,3121.98,"the things that we want to predict the possible options are just 0 and 1. We can't really at least directly work with this function value here we get out of that. So we use this kind of decision boundary if it's equal or greater than 0 and then predict 1. So this is what we saw before. And then with this approach, at least in theory, it's kind of business as usual because what you can do is you can measure the error from a prediction. So if you are, let's say, here and we predicted a minus."
3121.98,3150.11,"This means here that w times d is greater or equal to 0. This is below the line, let's say here. And we predict minus. And the true value is actually also minus. Our error is 0. Kind of makes sense. But if we're here and the value is plus instead, the squared error is 1. And why 1? Because the only features we can predict is 0 and 1. So no matter how you tweak it, 0 minus 1 squared is 1. 1 minus 0 squared is also 1. So the error that you have is either also"
3150.11,3180.82,"1 or 0, these are the only possibilities here because of our discrete prediction here. But either you are right or you are wrong is kind of also intuition. But this also works with the definitions we had before, with the sum of squared errors, because 1 squared is just 1 and 0 squared is just 0. So what we did so far is this binary classification based on a line, but we did not really consider the closeness to the decision boundary yet. We only used it to predict here."
3180.82,3209.23,introduces some problems we will see in just a moment before that we have one more example from the book we use in the lecture so there we have rpm so once per minute and vibration of like a manufacturing process let's say and we have the outcome so the status of the produce good which is either good or faulty so if the part is good or faulty and faulty is represented as a triangle here and good as a plus here we again intuitively okay we could draw maybe a line like this to separate them
3209.23,3235.31,using a regression function so we can do that again so let's say we found this line here and then we did what you also just asked before how do we know now which prediction is which which values are below and above the line you just plug values in and in this case if you plug in some ways you notice that if you have this this line defined like this like equal to zero is what we plot here then below the line means that the
3235.31,3266.16,"value here is greater than zero, so what we had in the example before as well. So here is greater than zero, and there we will predict faulty. And above the line, we have values less than zero. And this would be this part here then. And then we do, just as we did before, we somehow have to assign numbers to them. So let's say below the line, we do what we just did before. We assign a run to calculate the error. And for good, we say the value is zero if you predict, like above the line."
3266.38,3296.66,"And if you plot this now, we would have this three-dimensional plot again, where we have the vibration here and the RPM. And this is our decision boundary. So maybe the surface here is W times D, so the function value. And our decision boundary, remember, was exactly where this line is zero. So this is exactly the space where it's zero. And above that, we would predict an error. And below that, we would predict a good part. So here's our decision boundaries. And what this means then also is that if we're here,"
3297.2,3323.86,"Like yeah, we would predict an error, but if you just take one small step to here you pretty good, but it's very very steep effect and also I mean the error here goes from being zero if it's like also an error for real to being one the like the measured error let's say and This is what is wrong here. So if you had to have the decision here you see we have this kind of steep"
3324.14,3353.17,"steep curve, which kind of, okay, here we predict an error, and here we predict good, but in between, the decision boundary is kind of, maybe if you define your function correctly, it's at least defined, but it's not a smooth surface. So this also means that we can't do the approach from before because we don't have these properties. So here we have the decision, but you can imagine that if you plug this into the error function, you also get a non-continuous surface, so you can't do the gradient descent approach without any modifications. And what you need to do,"
3353.17,3389.25,"is you need to smooth things out. So you need to somehow wrap it into a function that now if you predict this value and then predict, let's say, value just below that, in the moment, the difference is not that extreme. Because you need a continuous function in the convex space to do the gradient descent approach we presented before. OK, yeah? Yeah, that's also a good question. So what happens is that we kind of make our prediction based on this separating line. So if it's above this line, we say it's good."
3389.25,3416.78,let's say we say it's good and above the line we say it's an error so we have kind of our w times d gives us a continuous value again and this is nice and smooth and so on but we make this decision based on if it's greater or equal than zero or not and this is then very abrupt so this is where the function gets non-continuous and we encounter all of these problems but we also somehow need to do that right because we want to predict zero and run and not some value kind of indicating anything in between
3419.12,3451.9,"Okay, so what we want to do is to smooth things out, and this is where logistic regression comes into play. So this is an approach to deal with this discontinuity of the surface, and logistic regression makes this step function, which is not smooth, smooth again. For this logistic regression, it's named after the logistic function shown here at the top. This is also known as the sigmoid function, maybe. It's defined as logistic of x is 1 divided by 1 plus e to the power of minus x."
3451.9,3476.11,"So here, of course, is Euler's number. And here's some nice properties. For instance, if you plug in 0 here, so we also have a plot of the function, we get a value of 0.5 from the logistic function. And if you plug in very, very high values, positive high, let's say, we get a value very close to 1, of course, never reaching it in theory. And if you plug in a very large negative number, we get a value almost 0."
3476.11,3503.02,"So this is the distribution we see. And also, we notice it's smooth again. And also, let's say, the steepness of the curve is also quite high. So from here to here, it increases quite rapidly, while having this smoothness kind of smoothing out at the ends. And what this is, yeah?"
3516.05,3545.74,"Yes, so I mean, there are multiple things here. You can, of course, also tweak this function slightly to make the steepness kind of increase or decrease. And what is useful here, we will see that later, is that it maps our function value of our line, W times D, to this space between 0 and 1. So it's now kind of, there's also some interpretation with probability, because we have, but maybe I will come to that later. Hopefully it will answer your question."
3545.74,3568.42,"Okay. Yeah. Also, one thing just to note here, we will not do another derivative, I promise, but the derivative of the logistic function also has some nice properties. It's quite easy to compute and also then the space is convex again. And what we do now is we plug this logistic function in front of our line. So in front of our w times d, kind of smoothing things out."
3568.42,3599.54,"And what we had before is kind of this decision boundary, where we abrupt. And now we don't have this case statement here anymore, 1 or 0. But we get a continuous value between 0 and 1. This is the nice property of the logistic function here. But the space is smooth again. And just to note, so where do we plug it in? Of course, here for x. So we have 1 divided by 1 plus e to the power of minus w times d. And if you take a look at the data set before, this is how it looks like then. So of course, we just plug in the values."
3599.54,3630.54,"smooth surface, and we still indicate this decision boundary here, which is now conveniently positioned near the 0.5 value. We saw that also before, if we have a value of x equal to 0, which is how we define the line, we get a value of 0.5 from the logistic function. And this is exactly the case here. And this, in combination to this 1 and 0 as the upper and lower limits, allows also for a probabilistic interpretation. So if we have a value here from our logistic function plug-in,"
3630.54,3658.27,"for instance, and it's here, up here, we're very sure that we predict one class. If we're here, we're also very sure that we predict the other class. But in between, we're kind of not so sure, and this is then nicely captured by this value on the line itself, 0.5. So if you would interpret this as a probability of the faulty or good part, this would also intuitively correspond to what you would predict. You're not so sure, could be either way. This also corresponds to"
3658.27,3685.6,"this 2D mapping here, so there we also have exactly the case if we're very far away from the line, we're very sure it's a positive instance, so not faulty, but if we are very far in that direction, we are very sure that it's not plus, so it's a faulty part. And here in the middle, very close to the line, we're not so sure. And this is then captured by this prediction value because now in the logistic function as a transformer, let's say, we have the case that"
3685.6,3712.56,"we also incorporate it in our weights. The error increases if we are predicting it to be a very short case of, let's say, a plus. But the actual instance is a faulty part. So here we take this distance to the line into account. And what this means then is that we optimize that as well and then get a nicely separating function and for free, basically, this probabilistic interpretation."
3712.78,3743.63,"And with that, we can basically do the same gradient descent approach as before. I didn't show you derivative and everything, but we kind of start with an initially randomly introduced separating line, which is not that good at separating values. And then we update it step by step until we reach this line here, which nicely separates the instances. And the error now also kind of decreases. So from before, it was very high initially. Then once we get to a decently good explanation,"
3743.63,3793.3,"It decreases, and we have this smoothness at the end where we also slowly then converge to an error value that is kind of stable. And this is done exactly like shown before, using this gradient descent approach of walking down the mountain and then stopping once there are no more improvements to be made. And this is then, again, the minimum, basically. Any questions regarding logistic regression so far? Yeah? No, but here happens. So the 1, 2, 3, 4, 5 corresponds to different steps."
3793.3,3827.95,"So steps in the gradient descent approach. So you start somewhere at one. Let's say this is the initial function. And you do one step updating the weights of the function to, again, step two. I think here is a selection of intermediate models. So this is not really maybe one step, but could also be multiple ones. But the order here remains the same. After some amount of steps, we are at the next one. OK, yeah? Yes, we will cover that at the end of the lecture. Yeah, that's a good point. And I will not give it away, but we will see that in maybe a few minutes."
3827.95,3854.46,"So maybe one thing I want to go over quickly once again is that we saw the smoothness here for the decision of our path, so kind of the value that our model yields. We didn't really show that the error is also smooth, but you can maybe imagine that if you go from this to this and plug in the model value in your derivative, the same thing also happens for the derivative of the"
3854.46,3883.81,"of the error and for the error itself, right? Because our prediction kind of has this rapid change. The same also applies for our error. If we somehow slowly change one of those from being above zero to below zero, you have this steep increase as well in the error function and the derivative is not easy to build and not continuous. And the space is not convex of the error. That's maybe too, we mentioned this is not the same figure of the error we saw before, but this is our decision, right? But the same."
3883.81,3910.02,ideas that it's not continuous and has some problems also applies if you then plug it into the error function and look at that okay so with that we kind of summarize the logistic regression part so here we looked at as input still continuous descriptive features with one head encoding and so on you can also incorporate non-continuous descriptive features but our target feature was binary and it was categorical so
3910.02,3935.49,"In just a moment, we'll also look into the cases where it's not binary. So if you have not just plus and minuses, let's say, positive or negative instances, but more classes. And the idea of the logistic regression can be extended to that as well. So what we saw here is that we get, as an output from the logistic regression, first a separating line, which allows us to do real-life predictions."
3935.49,3962.74,"positive or negative, but we, in addition to that, also get this indication of certainty. So we have this function from the heuristic function here, which gives us basically a value between 0 and 1, how sure we are that is of one of the classes. It's also sometimes useful, because maybe the binary classifier inherently has to give you a value of 0 and 1, or predict one of the possible values, even though it might not be very certain. So this is also a nice property that you can use."
3962.74,4002.38,"see if the logistic regression model is sure about the prediction or not. Yeah? Yeah, exactly. So it's kind of hard to talk about that, because at least what we did in this lecture is we just did the logistic regression. We didn't really explain how we would do it if you follow strictly the normal linear regression part without the logistic function. But what you would expect is that it has an influence, because the logistic function does not have this binary decision anymore, but also continues"
4002.38,4026.16,feature space and also considers how close things are to the decision boundary so this also yields then results which might not be let's say optimal if you consider only the binary classification yeah also next lecture there will be part on svms where like a different approach to that is showcased okay so now that we still have some time for
4026.16,4058.8,extensions let's look at two extensions so we first get nonlinear dependencies in our data and then secondly multinomial is exactly what you asked about so if you do not have a binary classification task but you have different classes we can choose from and we want to predict but let's first start with like normal regression and nonlinear relationships so in this data here we have a new data set and our features are the rain that let's say a plant i don't know where this data is from experience and the growth rate of the plant
4059.18,4090.24,"And maybe looking at the numbers already gives you some hints, but if you plot these values, you instantly see that we are now running into a problem. So what is the problem here? Anybody has any guesses if you want to do our normal linear regression? Yeah? Yeah. So no simple linear function, let's say, does really a good job at explaining our feature set. This is something that we call the representational bias of the linear regression. We can only learn"
4090.24,4116.99,"linear functions, so we will learn a linear function also in this case, even if it does not really disrupt our data well. And then you have to be careful, because for many of the techniques we've seen in the lecture, you can almost always apply them, but if it really makes sense to apply them, it's a different question. And also then if the final model is really a good fit, it might be the best one you've found in this feature space, but you can maybe think sometimes a bit outside the box to find even better models. So here we would"
4116.99,4149.38,"Maybe you have a different relationship in mind. Anybody has any idea of what relationship would make more sense than just the simple linear one? Yeah? Any idea of what degree of polynomial you will need? Yeah? Sorry? Second, yeah. Second is a good idea. I think it's also a nice curve that we fit. So our question initially is, OK, how can we still handle this relationship?"
4149.38,4177.49,"train the well-performing model, which nicely describes the data using the approach we just saw. So we do not want to change anything there. We have some mass properties with the derivatives and so on. We do not want to mess anything of that up. And how can we still use this linear machinery, the gradient descent approach, but also discover nonlinear relationships? And the idea is here that we can just add new descriptive features as input. So we do basically a pre-processing step, a transformation step before, where we"
4177.49,4204.96,"handle nonlinear relationships by kind of adding new features which are transformations of existing features. So for the rain example before, we have the normal rain feature, let's say, which was in our data also initially. And now we add a new descriptive feature, which is basically the square value of the rain. And we can, of course, do that, right? It's just our data set. And actually, we just add a new column and maybe drag a formula down because we have this information for all of our data. It's simply computed from existing features, of course."
4204.96,4234.58,"at least in theory you could also combine different features, but here we look at more the simple case that you do some simple transformation of one of the features. So here we build the square value of the rain as a new descriptive feature and add that to our dataset to the normal linear regression, and what we get is then a function which has the weight for like, okay it's written like this, but this is just the constant factor again, so the y-intercept let's say. Here we have the normal slope of the normal rain feature, and here we have the slope of the rain squared feature."
4235.15,4260.51,"And this actually also works. So here, if we do that for our data set, we have again the gradient descent. We do a lot of steps. But at the end, we have a line that nicely describes our data without changing anything else from the approaches. So this is our final model we get there. And just just maybe to show you that it's quite easy actually to extend this. But there's one trick maybe hidden here. So how did we know?"
4260.51,4286.0,"that we should add this square function, so the second degree polynomial. There you of course have to either look sharply at the data, and I mean you figured it out here, but there are infinite possibilities of features you could add as kind of transformations of existing features. You can look at the logarithm of things, the exponential and so on. So there you have to at least give some input or give some functions to consider, because otherwise"
4286.0,4311.78,"There is no really an approach to test all possible functions. It's just a too large feature space or an infinite feature space. But what we can do is do some of the visual analytics parts we saw before, and then try from that to maybe come up with a few functions, try them out, and see if they perform well at the end. And also look at the discovered model maybe. The same approach can also be done for logistic regression. So there we do not now."
4311.78,4339.17,find any so in this data set we can't find any clear lines separating the instances but maybe there's also like a higher order polynomial which describes the decision boundary so maybe here we would have something like this and here up again so this may be the intuition behind it and the approach works exactly the same so we add a new descriptive feature use it also to train our logistic regression and then we do gradient descent we have different steps so first we have this model
4339.17,4373.84,"Then we update it, update it, update it. And at the end, we have this, I think, third degree polynomial here, which nicely describes the separation line. And everything else also here stays the same. Are there any questions regarding handling nonlinear dependencies in the data? Yeah? Yeah, so what I mean especially is there's no easy way to automatically determine the function, which kind of"
4373.84,4402.83,fits the data so what you do at least in practice is that you look at the relationships in your data and see if there may be some exponential some some quadratic dependencies between like your outcome feature and the descriptor one of the descriptor features uh of course what you can also do is just come up with a set of let's say common functions and just for them at least try things out and see how well the model performs but this is not really a part of the or has anything to do with the regression itself you just have to give that as input basically yeah any other questions
4406.22,4439.36,that was not a question i hope okay so the last part for today is now what you asked about earlier so handling multinomial regression where we have multiple different classes so before we only had binary classes yeah okay yeah so before we always had binary decisions like true or false or something like that but we can also do a similar approach where if you have multiple categorical features sorry not multiple categorical features but multiple classes of our target feature
4439.36,4465.62,"Let's say here in this data set we have three different classes, single, business and family. And for them the kind of idea of what you can do to make this somehow binary is you consider one versus the rest. For each of these features, for single, for business and for family, you first learn logistic regression functions predicting if it's single or not single, business or not business, family or non-family."
4465.87,4498.0,"And if you trained, so for them, I think it's clear that it's easy again. So those are binary decisions again. So you can just use the logistic regression approach we saw before and learn this decision boundary here. And what you do then at the end is you apply maybe some normalization. So maybe take a look at an example. So here we again have now kind of three logistic regressions in one. So here we have the three different lines you can maybe see. And they start to separate the data into these binary classes for each of these feature values."
4498.0,4526.51,and then let's say we learn this separation here at the end and we also of course at the end want to get a classification which actually predicts one of these values so for each of the possible value in our feature space we want to predict if it's single business and family and what you do there is that you choose the one with the which has the kind of highest certainty that is the positive case so let's say would be up here for the single ones up here for business
4526.51,4553.04,"So here the probability, the certainty of the model is very high. And you do some normalization maybe, see the book for more details on that. And then for each of these possible points here, you choose the one which has the highest, most certain prediction for the positive instance. So for, in this case, family, business, and single. And this is everything that there is to it. So normalization here, I'm going into much detail. But after that,"
4553.04,4590.22,"considering just the different separate logistic regression functions, combining them in that way is like this classification technique where you can then for a new instance, let's say you get, predict if it's family, single or business. I hope that's clear. Any questions regarding the multinomial part? Okay. Yeah. I'm not so sure. So maybe in the assignment there could be something regarding that."
4590.38,4621.58,"For the exercise that is tomorrow, I'm not so sure. I don't think there is an exercise regarding multinomial dependencies. But of course, you can also ask questions regarding putting that. OK. If there are no more questions regarding the multinomial part, let's come to an end. I think I'm a bit early. Maybe I talked too fast at certain times. I hope you could still understand most parts of this lecture. So let's look at a short summary of what we saw today. We started out with the simple linear regression idea."
4621.58,4652.19,"as an error-based learning approach. So when we introduce our model and then iteratively update it to lower the error. And in general, this technique can be done for supervised learning only. Because you somehow need to measure this error, you have to have labels in your data. Linear regression has very good support for continuous features. But with some of the extensions we saw, we can also handle categorical variables. So for the target feature, this is then logistic regression at the end. But for the descriptive features, we can then use one-hand encoding or things like that."
4652.19,4679.49,"Yeah. So in the next lecture, which will be, again, given by Professor van der Aals, we take a look at SVM, so support vector machines. And the idea here is rather similar to normal linear regression, that you have a separating line or plane, whatever dimension you're talking in, between instances. But here the idea is, contrary to what we had before, that something like this instance here, which is very far off from the decision boundary,"
4679.49,4708.3,"should not have an effect in the difference of error if it's here or here. So they are both very far away from our decision boundary, so they're not anywhere close to changing our decision. So they should not be considered to the same extent. And what is done here in theory, you can imagine this maybe like an air mattress you have here, and then you pump it up. So we want to increase the free space between your decision boundary, where there are no instances. And this area is where you would be very, very uncertain."
4708.3,4736.24,"want to reduce the number of instances that are there or find the largest kind of space you can blow up this air mattress to not catch any of the instances here. So if you want to learn more about general regression and some of the examples we only talked about briefly in this lecture, you can take a look at this book here, especially chapter 7. We are right now in this part of the course, so we are just at the lecture on regression. Tomorrow there's going to be the exercise on decision trees and regression."
4736.24,4764.53,"I, of course, encourage all of you to go there and maybe look at the exercise sheet beforehand. Also, what is something that comes up rather soon is the publication of the first assignment. So there you should, in Moodle, register for a group and also try to at least free some time because you have to spend some time to work on that and hand it in. With that said, thanks for your attention. I hope I was an okay replacement for Professor van der Eyls and see you in the next exercise maybe."
