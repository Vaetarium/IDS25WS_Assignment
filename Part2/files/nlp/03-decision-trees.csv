start,end,text
4.11,32.82,"Okay, let's try this again now. So, good morning, my name is Vicky. I will be presenting decision trees and you will have Professor Van der Alst back next week. On Wednesday, Aaron will be here. So, if you cannot hear me in case at some point I get pretty silent, then please raise your hand and tell me."
33.33,64.54,other than that then let's just start and if you have questions you can anytime also just raise your hand. So what is the outline of today's lecture? We will first like very briefly talk about supervised learning since decision trees are is the first kind of presentation on supervised learning and then in the following weeks you will have a few more. Then again briefly we will talk about
64.54,86.75,"how one should not force or torture the data to say something when maybe there is no such information in it. And then finally we will introduce decision trees after which we will talk about entropy because that's like a main concept that will help us decide, help us build the decision tree."
86.75,119.74,"And then we will go to the ID3 algorithm, which is the initial algorithm for decision trees. And we will finish with some variations of the algorithm and also how to handle continuous variables. So supervised learning. Our data is, let's say, in this format where each row represents one instance and then each column is a descriptive feature. Or a feature, not a descriptive feature. And then..."
119.74,150.93,"all of them except for one are descriptive features and then we have one target feature. And the idea with supervised learning is that we want in some way to be able to predict the target feature given the values of the descriptive features. So we want some kind of function that will tell us the output. How do we? So, right?"
150.93,178.78,before we had it kind of on on a feature level and now let's say we have if we replace specific values we go from descriptive features let's say order id that is three two four two four and then some product some price and some date we want to know if there is going to be complaint or not um and here we will see in the in the following
178.78,208.42,"kind of lectures that there are different options for this, let's say, F or the method representing the supervised prediction. However, today we are going to talk about decision trees. So we will come back to how decision trees look later on more concretely, but basically at each node we try for some descriptive feature to make a decision whether we go left or right."
208.42,237.09,"And then we continue that as long as we kind of need until we get to some leaf node where we will see whether the label, where we will predict the target label basically. But before going to decision trees, kind of this part where it's let the data speak and do not force the data. And we start here by..."
237.09,258.48,"talking about statistics and statistics have been there for quite a while, like John Grant in the 17th century already, he recorded deaths or used death records to be able to predict life expectancy of a person at a particular age."
258.48,286.82,"So he was the first to create such a live table. I mean, later on they are still used also in insurance companies. But basically we will see that this is like four centuries ago. Then in the 19th century, let's say more concrete terms that we still use today, like variance, normal distribution, correlation."
286.82,316.19,"and linear regression were introduced or reintroduced by Francis Galton. So we can see that what we will be talking in the next lecture, or at least the basis for it, has been there for quite some time. But, however, only lately or in the last, what, 30, 40 years, maybe there has been more success. And why this is the case? Because, let's say,"
316.19,342.78,"in the beginnings, statisticians focused on proving that nothing can be concluded with certainty. And this is of course exaggerated a bit, but kind of this was the idea that nothing we claim, we can be certain about it. And while this is true, let's say the data mining and then data science community was more pragmatic and was"
342.78,372.18,"kind of saying, okay, even if I cannot say something with certainty, maybe I can still get useful information from it and make some predictions. So I was not there for it, but apparently there was like this clash where, for example, statisticians would consider major breakthroughs in data science as data phishing, data snooping, or data dredging."
372.75,389.36,"These are recommendations by the professor. The one on the left talks more about this culture where most of the statisticians, for example, had this assumption that nature behaves according to some model."
389.36,420.21,"and focused on parameter estimation, and only 2% were more pragmatic and tried to work with predictive functions. And the one on the right is basically a book that actually is from one of the 2% statisticians, so maybe you can have a look. However, although everything of this might be true, we should still be careful. And now, let's say a sketch that represents some risk about..."
420.21,448.3,not taking statistics seriously is we have this conversation where jelly beans cause acne and then basically then scientists investigate but they don't find any link between jelly beans and acne and acne with a confidence of 95% but still chance of look of 5%.
448.37,477.63,"And then someone can say, okay, that's it. But someone else might say, actually, I think maybe there is a specific color that causes the acne, so let's investigate purple jelly beans, brown jelly beans, pink jelly beans, yellow jelly beans, I don't know, all the colors, maybe not all, but 20 colors, and then, oops, for green jelly beans, we can find such a link. I think it was..."
477.63,505.31,Yes. So then we can have like this news article saying okay there is a link between jelly beans and acne but as we see this 5% chance of coincidence is actually 1 out of 20 and if we test 20 colors then it might be that 1 out of 20 actually it is a coincidence. So one should be very careful like
505.31,534.06,"should still know the basic rules of mathematics and statistics before then making claims in the end. Right, and this is what kind of I said, there are risks when testing many hypotheses, you might overfit the data, you might underfit the data, there might be bias in the data or there might even be bias in the representation. So, kind of the lesson here is"
534.06,562.91,"One should be careful, right, because we can make wrong conclusions, but still one should also be pragmatic and not just assume that nothing can be done because data is dirty or biased. Data will always be dirty and biased, so you should start by summarizing the data, and this even from the start can be quite helpful. And now what we also see is this shift from having, let's say,"
562.91,594.74,a small data set or a sample to a big data set or using all of the data that are available and only recently kind of this we had even the opportunity to basically use all the data that we have. So that was kind of for the introduction part. Now we are going to focus on decision trees.
594.74,624.62,"And we go back to our table where we said, okay, each row here is an instance and each column is a feature. And now we want to use the descriptive feature, which are drinker, smoker and wait, to predict the target feature. The target feature in our case have two class labels. One is young and another is old."
624.78,654.45,"how decision trees look, right? We will see later how we build them, but the idea is that, okay, at each internal node, including the root, we have one feature, one of the descriptive features, and we want to test then each instance whether for that descriptive feature we have the answer kind of yes or no for smoker, and then we go from there. For the leaf nodes,"
654.45,681.38,"like here, for example, young. We have also some numbers. And here, from representation to representation, it might be different. But in our case, here we take that we have at this node 195 smokers and 184 of them are young."
681.38,711.18,"and 11 are misclassified. So for 11, we say they are young, or like the life expectancy is that they die young. However, that's not true. Okay, so this number here, the first one is all, and the second one is of the misclassifications, right? Some representation might have left the correctly classified and right the incorrectly classified. So, yeah, that's something to check."
711.22,737.57,and then that is for yes and for no let's say we still don't have a clear decision but we need to check another descriptive feature and the descriptive feature we check is for example drinker and then we again can go left or right yes or no for no we again end in a leave note while for yes we still need to continue checking and as you can see here like
737.57,763.47,descriptive features and including the target feature are categorical. So let's for example look at now this one where we also have numeric values. So this is basically study results for students and we have grades for different courses and we try to predict
763.47,789.47,"the target feature is whether they pass or not for their studies. The grades here, the professor said, are from the Netherlands, so it's not German grades. And what we can then do, okay, yeah, the class label, in this case, it's three, and it's still categorical, right? You can also have a numerical target feature, but we will see that later."
789.47,816.61,"And there are three class labels, cum laude, passed and failed. And an example decision tree would now be here, like in the root node where we have all the instances, we split them based on whether they have taken or not taken logic, whether they have a grade less than 8 or a grade equal or larger than 8."
816.61,839.39,"And as you can see, the split is again categorical because we have three options. But the difference from before is that now this is not something that one can directly find in the data, but basically we make the decision based on whether it's above or below 8. So there is a difference."
839.39,870.61,"So basically, same kind of strategy. We have the leave notes where we already give a label, and if an instance is able to get to a leave note, we'll be assigned that label. Same, we have 79 in total arrived here, 69 failed, and 10 we label them as failed, but actually they either passed or finished cum laude. So 10 misclassifications."
871.09,896.53,"So, what I said before is that we have three types of nodes, the root node, internal nodes and leaf nodes. The root node is also an interior node. The difference is that the root node is the only one that has all data instances or represents all data instances. In all the interior nodes, we then have subsets of the original data set."
896.59,925.78,"And the interior nodes partition the set basically then in these subsets based on the descriptive feature. So as we saw, okay, depending on whether someone is a smoker or not, we split the two datasets and from one we get two. And the leave nodes have a label, which is the target feature label, and the goal is that it will correspond to a homogeneous group of instances. Yes?"
930.58,965.82,"No, not the interior nodes. The root node contains kind of the entire, like not contains, but represents the entire data set. So the root node is the only one that I would get the entire table here. And then once kind of I have here a split for logic, I immediately then in all of the other nodes I have sub data sets. So I won't have the entire data set. Yes. And then"
965.82,996.16,"for every internal node you continue doing that. So you have one data set here and then you kind of split and then you have subsets of this one here and here. And then if I get the union, for example, of the data sets in each child node, I will get to the data set in the parent node. So if I get the..."
996.16,1026.26,"data sets that are represented by each child node, so I have a data set here, here and here, right? If I take their union, like if I put them in one table, I will get the data set that is in this node. Yeah? Yeah. Okay. Yes. So that is for, let's say, the summarization. So now this is an example from the book."
1026.26,1056.3,"We have three descriptive features, so we are basically trying to predict if an email is spam or ham. And ham is actually a real term, it's not some random. So we have three descriptive features, suspicious words, unknown sender, and whether the email contains images or not. And then we try to predict the class, whether it's spam or ham."
1056.4,1086.32,"One way to do that is this, for example, tree here. And if you try to now kind of for each instance to go through the nodes, you will see that for all of them, basically, we will have the correct classification in a way. So let's say if we take the first instance, does anyone want to tell me which branch we take?"
1091.89,1115.42,"Yeah? Yeah? So we say contains images is, right, we can also do this, contain images is true, right, for the first one, whether it has suspicious words, also true, then we label it as spam, and basically the class label is also spam. And for these three,"
1115.42,1140.54,"all of the instances are correctly classified. So we won't go through all of them, but you can see here basically the IDs where each one maps, right? Then we have this tree, right? And for this one, we have the same. All are correctly classified. And actually, it's also easy to see from the data, like here we have for suspicious words, the first three are true, the second three are false."
1140.54,1165.18,"And for the class, the first tree are spam and the second tree are ham. So we can see that we have this one-to-one mapping, so it makes sense that all are correctly classified. Since now both basically describe the data correctly, usually one takes the simpler to be better."
1165.18,1194.75,"and kind of keywords like avoiding overfitting or applying Occam's rays or come to mind. And we will see that the algorithm we will present actually prefers shallow trees. And for now, although this might not be, let's say, in 100% of the cases true, but now we will assume that we want simpler trees if, let's say, multiple trees exist that can describe our data."
1194.75,1224.64,"How do we kind of achieve now this idea to have like simpler trees, to force us building simpler trees? What we want to do is we start with the data set, right? In the root node, this is our entire data set. And now it's simplified, right? We have balls of three different colors. And what we want to basically do is then split. And as you see here, what I said, kind of the union,"
1224.64,1251.2,"of the data sets in this tree is the one here and we want to continue splitting in a way such that going from the root to the leaves we become more and more homogeneous. So the subsets we have are more and more homogeneous because then I can easily say here, okay, here I will predict red, here I will predict green,"
1251.2,1286.16,"And here it's not perfect, but I would go with blue probably, and here I would go with red, right? I will make mistakes, but still it's much easier than saying here red. Yes, so this information gain or improvement in knowledge will make the predictability of the class label kind of easier. Okay, entropy. So..."
1286.35,1316.21,"What is the intuition for entropy? So basically we will use entropy for disinformation gain to measure how more and more homogeneous, let's say, our data sets are. But let's start with this. So because it's 8.30 Monday, I feel like maybe many of you are sleeping. So I will ask you the following question. Given a deck of cards,"
1316.21,1344.88,"and a deck of cards looks like this, right? All of my decks will have, what, 12 cards, and I can have repetition. Right here, I have ace, spade, and king of hearts. My question to you is, would you play the following game? You pick one card, right? And here you have two options. One is the ace of spades, the other is king of hearts."
1344.88,1380.21,"Then we kind of turn the deck, and if I pick a card on random from the deck, you get money. If it's the same with the one that you picked, you get money, otherwise you lose money. Did you understand the game? I see confused people. Anyone didn't understand the game? You didn't understand the game? Okay. It's still in it. Yes. So, yeah? Yes. Yes. Yeah."
1380.21,1411.3,"So you just kind of, you know, there are two options, right? So this is the deck of cards. I take a card. If it is the one that I said, you get money. Otherwise you lose money. Okay. And how we are going to do that just to kind of wake up maybe a bit. Um, I'm going to say three, two, one, and you're going to do this. Okay. So think about it. Are you going to bet on it? Three, two, one, go. Okay. Okay."
1411.3,1455.73,"Now I have this deck of cards. Would you now bet money? People are talking. Does anyone have a question? Yes. No, no. It's random, right? Okay. Three, two, one. Okay, like similar. How about now? How many of you, maybe this question, how many of you know which card they would pick if they play?"
1457.42,1490.86,"OK. How many know now? OK, so we kind of get the point, right? Now you have only one option, so you would pick that one. And how many now? OK, I didn't say 3, 2, 1, but I guess it still stays the same, right? So basically, we don't do this anymore, but the idea is that"
1490.99,1545.65,"The set, kind of when it's more homogeneous, like the one on the top left, it was quite loud. However, the set on the right bottom, you were all quiet. Can anyone say why? Yes. And you're sure that you're going to get money, kind of, right? Because there is no other option. The one that draws me will have to draw one of those."
1548.66,1582.61,"Anyone else has opinions? Yeah? What did you say? Yes, it is probability, right? Like we saw it was, maybe here now the order was also important, right? I went from higher probability to lower probability here, and then I went again to high and even higher, and then to very low. So, but still, it comes to, yes? I want to say it comes to the probability, kind of."
1583.09,1650.83,"Yeah? You make, you definitely then, yes. It's not zero. Yeah, so it's one out of what, 12. Yeah? Okay. And we talked about probability, okay, come back now. I know we had a break. So we talked about the probability, and right, the probability here was one, here was one out of 12."
1650.83,1681.87,"And the thing is that the entropy is kind of in the different direction. When the set is homogeneous, then the entropy is zero. This H here is the entropy. And then the lower the probability, the entropy goes up. And the interpretation is that entropy measures impurity, uncertainty, or incompressibility. Let's say another example."
1681.87,1711.34,"So same intuition, right, we have the measure of impurity or uncertainty when guessing and incompressibility. We will see that we start here with high entropy, right, then split. All of the nodes that have only balls from the same color have the entropy of zero, like we can see here, here, here. And then the ones that have more of one color and only one of the other,"
1711.34,1744.82,"For example, if we compare these two where we have three compared to one and two compared to one, we see that the entropy here is lower than the entropy here, but both of them are lower than, for example, this node and this node where the homogeneity is much worse. Okay? Any questions? Okay. So now this is kind of how we... Yeah?"
1744.82,1771.2,"Ah, no. OK. So this is how we go now from probability to entropy. And the idea is that probability goes from 0 to 1. And if we take the logarithm, for example, here from 0 to 1, we'll see that the logarithm basically then for probability of 1 is 0."
1771.2,1800.43,"And that is what we want for our entropy, right? Our set is homogeneous. And then basically goes to minus infinity the closer we go to zero. And since we don't want negative numbers, we just, let's say, swap this by having this minus in front. And then this part here, so that's the part here, right? And this part here basically says"
1800.43,1830.5,"how much each class will contribute to the impurity. And now if we kind of replace the numbers for the set here, we see we have 7 out of 14 balls are red, and then we take the logarithm base 2 of that, and then for the blue we have 3 out of 14, and for the green part we have 4 out of 4."
1830.5,1854.88,"14. And if we compute everything, then this is the entropy that we will get. Yes? Here? S is the base. We are going to continue from now on with base 2, so logarithm base 2 then something, the probability, because usually base 2 is used for kind of"
1854.88,1877.95,"has this connection to bits. But in general, if you change the s, you can try playing maybe, this graph will change like how fast, for example, goes to minus infinity. So it's just kind of how it's still going to have the same effect, but so always"
1877.95,1910.9,"higher probability will have lower entropy, so it will stay the same. The only difference is like how this graph looks, like whether it will look like this or then we have something like this and then immediately goes down and so on. I think that answered that. Okay. Okay. Now let's try again kind of with the formula just to maybe remember it. So now we have, but someone is talking."
1910.9,1937.18,"So I will ask whoever is talking to either talk quietly or decide that maybe then they want to leave. Yeah? Thanks. So now in this set, we have five instances or five balls. Three of them are green and two are red. So now if we kind of do the, we replace, we have two out of five for the red times the logarithm base two, two out of five."
1937.18,1963.23,"plus 3 out of 5 that are for the green and the logarithm to base 2 of 3 out of 5. And computing it, now we see, okay, it looks a bit more homogeneous than the one before and the entropy went down. For probability of 1, right, when I know that all of my balls have the same color, so there is no chance I'm going to choose another one,"
1963.23,2000.59,"If I do then the logarithm, I have logarithm base two out of one is basically zero. Yeah, you have a question? No, so no matter how many kind of levels, like how many options the feature has, we always use the same logarithm. And as I said, here we will always lose log two. In general, you can replace it, but then you still need to use the same base for all of them. Yeah?"
2003.5,2034.1,"Okay, another question. So now you have L colors and N balls, right? What is the distribution of the N instances over the L values such that the entropy is lowest? And the second question is the entropy is highest, right? So this connects to what we did before. It is kind of same story. Anyone has an answer? Yes?"
2048.66,2076.78,"Correct. So if we give, let's say if we color all instances red, then we have the lowest entropy because the probability is 1. And then if we all color them differently, we will have the highest entropy because basically the probability is also lowest in that case. So, right, if we assume that we can..."
2076.78,2106.29,"divide N with L, then we basically have k, k, k for each color. The table here, it shows what is the maximal entropy given how many colors you have. So if you have only one color, there is no option, right? I know that it's going to be that color, the probability is one, the maximal entropy is zero. If I have two colors, and because now we are using two bits,"
2106.45,2140.72,"basically the entropy will be 1. The more kind of I go, now I go above 1, but basically the more options I have, the highest the entropy can be. So as we said, the aim is to have pure leaves. So what we are now kind of have in the root node, we will have different instances with different colors. And then we assume"
2140.72,2170.8,"that we have nine leaves in the end. Each leaf has instances only of one color except, let's say, for one of them where we still have the colors mixed. Our algorithm that we will see later will almost never return this, almost, because it will try to kind of equally make it homogeneous. It might happen."
2170.8,2224.91,"but this is just to kind of consider only the entropy, right? Yes? Yes, except for this one, right? Yeah. So it is just, so they will still have the same ordering, right? For two, it's going to be smaller than three, but it's just they all are going to be smaller. So that's why you never mix bases when you do the computations for one data set."
2227.5,2258.03,"Right? We were here. So each leaf is only one color instances and except for one that is mixed. So we want to compute the weighted average of the entropy, the overall entropy, but computed split by the boxes and then taken the weighted average and the entropy if we have all of them together. So the entropy of the root basically."
2259.18,2288.99,"So for all homogeneous, we already talked about this, right? Probability one, entropy zero. And here, let's say for the box in the middle, in total we have eight colors and two instances for each. So basically what we do is we sum for each color and then we take one eight."
2288.99,2317.94,"is the probability to have that color times log base 2 of 1 8 for the entropy. And the result we get is 3. So the weighted average would be now, and why it's weighted, because maybe in one box I have more instances than another. In this case, the weight for each one is the same because in each box there are the same amount of instances."
2317.94,2349.65,"which is 16 out of 144 and for 8 of them it's 0 and only for 1 is 3 and then this is the result we get. Now my question before I go to the next slide, if I mix all of them together, does anyone know the entropy kind of out of hand? Yes?"
2350.1,2408.93,"Three. Why? Exactly. Yeah? No, so this three is for the middle box. So these three. So here each entropy is for one box and here is if we take the overall entropy but considering that they are split in boxes. Yes? Like this is now computations only afterwards. So E is equal to this and then if I, because I have eight"
2408.93,2440.34,"For these that are multiplied by zero, it's just computation. Yeah? So write what you said. It's right that now the next one is also three because if we just scale our data set, there is no actually, no change in the result. We still have the eight options and all are distributed the same. So whether I have only 16 instances or 144, it won't change the entropy of the set."
2441.26,2468.94,"Now, if we go, let's say, from this, where they are split, to the mixed ones, we have an information loss, and if we go the other way around, we have information gain, right? So here we have a lower entropy, here a higher entropy, so we are losing information, and here we actually gaining information. These are some other examples."
2468.94,2497.23,"I'm going to go quickly through them because we already talked about this. So the first example is everything is for one option, so the entropy is zero. Then the other one, everything is equally distributed. And then we have, again, someone there, I can see you, you're talking. Please."
2497.52,2528.22,"So we have here kind of scaling now. We still have the same distribution, right? Each has the same amount of instances. It's only not one but ten, and we can see the entropy doesn't change. And then everything else is in between, where, for example, here we know that from option one we have more instances than for the others. So it goes, let's say, lower than here where everything is equally distributed."
2528.22,2554.9,"and here it's even more clear that let's say most are from option one and each option then has only one instance. So which is why the entropy is even further lower. So just to see then the example from the book that we showed before with Spam and Ham, what we do is we compute the entropy"
2554.9,2585.7,"first on the entire data set, right? We haven't made any splits, so we want to know what is the entropy if we need to give a kind of a prediction in the beginning. And we have two options and they are equally distributed, so the entropy is one. I hope this is kind of clear by now. Then we have the different, let's say, descriptive features. Here we have, once we split the two"
2585.7,2620.77,"sub-datasets have homogeneous values, so both have entropy zero. The weighted one would also be zero. Yes? Yes. Yeah, sorry. So H is basically, this is just more precise in saying I'm using feature T and dataset D, right? And when the context is clear, here,"
2620.77,2650.54,"I know that this E is for this data set, I don't use the, let's say, the more complicated notation. So it is just E, but it has basically the same meaning. If I would replace now here with H, I would say the feature is suspicious words, and then, no, the feature is actually still the target one, but the data set is this one, right? So it's just more precise, and then the W means it's now weighted average."
2652.88,2676.22,"Okay, then we have for contains images, where we have here for true, we have one spam, one hem, so equal distribution, the entropy is one for two options, and here we have two with two, so entropy is again one. We again see that scaling basically doesn't change the entropy. For the unknown sender,"
2676.22,2711.7,"We have two spam and one ham for true, and one spam, two ham for false. So the entropy is in between zero and one, closer to one. And you can see, again, they have the same entropy, because if you don't consider the labels, it's just in reverse. One option is two times more frequent than the other. Yes? No, scale, I mean, I have one option spam, one option ham, and here I have two options spam and two options ham."
2712.11,2742.7,"Yeah, so that's what I mean, scale. So I have one option once, one option two times, one option once, one option two times, so basically I scale how many times I have that option. But still the distribution stays the same. That's what I mean, that the scale doesn't change the entropy, or the ratio doesn't change the entropy. Right, and here basically it's just..."
2742.7,2774.56,"kind of the computations. And then we can go to information gain, and then the information gain would be the entropy of the parent, right, in our case that's the root, minus the remaining entropy after we have split. So, right, this here, rem, it's basically the weighted entropy. And we go from, let's say, 1 minus 0, 1,"
2774.56,2803.18,one minus then the entropy of the other one 0.08 and the information gain for this one is zero and you can immediately decide that when I have low high entropy I have low information gain and then basically this is the best option. And now we are going to use this in the ID3 algorithm to decide which feature we are going to choose first.
2804.14,2833.3,"The ID3 algorithm was developed by Ross Kinlan in 1986, so quite a while ago, almost 40 years ago, and it's a predecessor of, let's say, more complex algorithms like C4.5, and the idea is that you compute the entropy for each feature, and then basically you, or actually,"
2833.36,2867.17,"Then you split the data set for the feature that has the maximum gain, the maximum gain, right, or minimal entropy, and you make a note in the tree, and then you split the data set for and rerun the algorithm again, right? Okay. So this is basically the pseudocode, won't go into details, but..."
2867.17,2888.5,"This part here talks about, okay, when do you stop, right? Because we said you go back and rerun the algorithm. So it's a recursion. So we need to stop at some point. And there are three reasons to stop. So you have a homogeneous data set or all instances have the same label."
2888.5,2918.88,"You have no more features to split on, you have used all of the descriptive features, and you still don't have homogeneous set, but there is nothing more to split on, or the data set is empty. And we will see an example soon. Then this part here says, right, pick the feature such that the information gain is maximal."
2918.88,2950.06,"Once, as I said, once a feature is picked, it doesn't make sense to use it again, at least for categorical values. So what you say, okay, from the feature set, we remove this feature. And then finally, once you have chosen the feature, you can split into your subsets, and then for each subset, you say, okay, run the algorithm again. We are going to see an example now, and hopefully it will become..."
2950.06,2979.65,"clearer. So let's say we have here an example where we try to predict vegetation based on stream, slope, and elevation, all categorical, and for vegetation we have three different options. And now if we try to first, right, because we are in the root, we have all of our instances, we try to compute the entropy, we have three out of seven are chaparral,"
2979.65,3009.15,and then we have log base two of that then two out of seven are riparian and two out of seven are conifer right and then if we compute this like we replace we we put our values in our formula and if we compute this this is the result we get um right so we have this now here and now the idea is right i want to split by feature and
3009.15,3040.43,"let's say stream can be true or false, slope can be flat, moderate or steep, and then for elevation we have four options. And if I do that I would split basically each the data set into subsets based on this value. Can someone tell me for stream true, I don't know how good you can see, but for stream true what would be the instances"
3040.43,3088.86,"in this set D1. Yes? Yes. And for false would be the rest. And then if I take flat, right, I have only one, it would be D5, and then moderate, it's also only D2, and the rest are steep. Right? This is clear? Okay. Now if we compute, let's say, the entropy for this,"
3088.86,3119.15,"data set, right, we still use the target feature to compute the entropy, we get 1.5, for this set here we would get 0.9183 and now if we take the weighted average here it would be 4 out of 7 times this, 3 out of 7 times this it would be 125. Here we see we have only one instance so the entropy is zero because we have only one option."
3119.6,3153.87,"Any questions? Yes? Remaining, kind of, it's entropy remaining after splitting. And because usually it always goes down, that's why it's remaining. So it is the EW from before. And then the information gain would be this entropy here minus the entropy here. And then we have these values."
3154.58,3198.32,"And basically, if we now look at this, the elevation has the highest information gain, lowest entropy, so that would be the first feature that we choose in our algorithm. Yes? Is it? I mean, I... Ah, because is it a PDF? Yeah, we will update it, okay? Yeah. So, yeah, because it's not actually animation, because I try to..."
3198.32,3228.91,yeah doesn't matter we will update it we will have the version um okay so now we split on elevation right we have low medium high highest and these are the um these are the kind of the subsets now the data sets given that elevation is low is this one and then we have this one is for elevation medium and so on and so on now another question um
3229.94,3274.27,"Here, for which data sets we would need to continue splitting? Yes? Here you mean the values? No, highest is the value for elevation. So this on the branches, it means the feature elevation has, for all of these instances, value of low. And for all of these instances, the elevation is highest. So if you go kind of see the original one, you see,"
3274.27,3318.13,"Basically, that's this value. So for which one, I can already give a label, and for which one, I have to keep splitting. Yes. Can you, without computing, just looking at the data, decide on which data feature we will split here next, and on which we will split here?"
3318.58,3354.8,"Okay, I choose someone else. Yes. Clear for everyone? Like you can all see it? It's because basically we have this match here, right? Here I cannot still differentiate, but here I can. And now basically once we do that, also that split, we have this tree and now if we go back to our algorithm of the stopping criterion, right?"
3354.83,3379.87,Here we stop because we have a homogeneous data set so we have a consensus and for all of them this is true except for this one it's just that for this value we don't have any instances so our data set is empty so there is nothing to split. The only thing that it's not kind of shown in this example is using all of the features and that would be if I have elevation
3379.87,3438.45,"slope, and then I had, let's say, stream here, and then I still haven't had a consensus, but I wouldn't have any more features to split on. Yes? Sorry, what do you mean? No, you cannot compute it, right? There is nothing, if you don't have any instances, there is no entropy that you can compute. Yeah? You mean which label you would give? Ah, okay."
3438.54,3504.0,"But then for which now? Yes? Yeah, so basically here. Here, right? Yeah, okay, now I see. It would be zero. Yeah, and this would be basically the final result. So now different variations of the algorithm. So one thing you can do differently is how you measure the information gain."
3504.0,3533.9,"And there are two alternatives that we're going to have a look at. One is information gain ratio and the other one is the Gini index. So the thing with the information gain is that if I have a feature that has multiple options, that means each data set or sub data set"
3533.9,3560.72,"will have less instances. So kind of they have this advantage of having more clean data sets and we saw this with elevation, right? The first feature that we chose was elevation because it had four options and for two we had completely homogeneous sets. With information gain ratio we basically try to kind of"
3560.72,3589.65,"correct this, right, to not give that much power to features that, I don't know, will have 100 options. And how do we do that? Is we take the information gain, however, we divide it with this part here, and I will explain what it is, but the intuition for this part here is that if I need, let's say, if I need to encode now this knowledge that I have,"
3589.78,3619.94,"What is the information that I need to encode a feature that has four options compared to a feature that has two options? And basically if I have two options, right, I can use only one bit, it's zero or one, but if I have four options, I would need to use then two bits. So I would need more information in order to just describe my feature. And this part basically measures that."
3619.94,3650.29,"with the consideration, like, how these instances are split, basically, between the options. Because it might be that the split puts almost everything only for one of them. You will see. I know you're confused, but I'm hopefully going to explain. Okay? So, this is everything now from before. We have..."
3650.29,3678.0,"our normal information gain, right, we start here and then we compute, we split on something, these are our two subsets and now let's say the entropy for this one is 0.8 something and here of course homogeneous it's zero. And here I have multiple options on which I can split, right, this feature has multiple options and now I have three out of the four data sets are homogeneous."
3678.13,3705.54,"So the information gain basically is lower for the one on the left and higher for the one on the right. However, as we said, we want to kind of at least punish a bit when we have that many options. So what we do, we have the information gain, but now we also compute this part here, that is the information needed to encode"
3705.54,3734.51,"the feature kind of. And that is because here we have two options and now the split is not, I don't count the target, so I don't count the colors, I don't count the target class, I count how many options in each of the boxes. So how many instances in each of my subsets. Here I have four and here I have two. Here I have two, two, one, one."
3734.83,3761.52,"Okay? And now basically you can use the same formula from before, we just don't use it on 3-1, which is for the target feature, we use it on the number of instances. And then we get these two entropies. So here we can see it's higher, here it's lower. And now if we divide by that, we will get a different number. Now the ratio is this divided by this."
3761.58,3788.46,"And these are the two values, and we can see now that depending on whether I use information gain or information gain ratio, I might make a different decision. Questions? Yes. So I will come back again in the end to this. It's not that we prefer one, right? It might be..."
3788.46,3817.33,"that in a specific case you prefer one over the other. We talked in the beginning, if you remember, about shallow trees, right, simpler trees. So it might be that I say I want trees that don't have that many branches, and if I split this very early because it has more, let's say, it has more of an opportunity to give me lower values for the entropy, it might be that my tree is not that..."
3817.33,3862.29,"It's not that simple, right? So I wouldn't say one is better than the other, right? It's an alternative. Okay? Questions? Yes? No. No, no. So I will have to see the instructions, but I will make sure to talk with the instructor to make it clear whether, for example, in the instruction you might always prefer one."
3862.29,3890.88,"Otherwise, it should be made clear in the task. Okay? Okay. The second alternative was the Gini index. So it has a similar aim, and what it tries to measure now, this one, is the probability of guessing wrong. Right? We talked about guessing when we had this deck of cards."
3890.88,3916.48,"When we give a deck of cards to Gini index, we'll tell you the probability that you will guess wrong. Since it's a probability, it has the advantage that the values are between 0 and 1. And it's not like no limit, like the more options you have, the higher it gets. And how we compute it? So we said it's guessing wrong."
3916.48,3949.18,"So what we are going to do is going to take the probability of 1 minus the probability that we guess right. And the probability to guess right for a given class would be the probability that we guess that class in the first place times the probability that we are going to be right, which is why it's the probability squared."
3949.18,3977.65,"So how do we do that? Let's say we again have the same data set, different splitting on different features. These are all splits. And now if I take the Gini here, I have, let's say, one fourth to guess red and one fourth to be right, that it's going to be red, and three fourth to guess green."
3977.65,4005.62,"and 3 times 3 fourth that I'm gonna be right. Right? And that's for the right. And 1 minus that is the wrong label. You can look at it from the other direction as well. It's just, this is like cleaner, but you can also say I have 3 fourth, right, to guess green, times 1 fourth to be wrong. So I basically draw red."
4005.71,4034.03,"and one-fourth to choose red, but then I have three-fourth probability to be wrong. And it will be the same number. It's just kind of the opposite computation. Here, I have, with probability one, I choose red, and I will be correct, which is why all of you did this for the deck of cards only of spaces, ace of spades."
4037.33,4067.95,"So on one, you need to choose, right? And you would choose, if you just use the distribution to choose, you would choose red in one out of four, right? Because it's one out of four. But then once you choose, you also need the probability whether your choice is correct or not. And the probability that it's going to be red, it's also one for it, right? So that's, as I said, in the one direction,"
4067.95,4103.73,in the different direction you can say I choose red with the probability of one fourth and three out of four times I will be wrong. Here as we see like here it's half right so it's gonna look the same. And now coming back to the question so as we can see that we might choose a different descriptive feature based on which
4103.73,4133.15,"which type of information gain we use, and there is no best answer. This is more now in the practical direction, as I said, for the instructions and for the exams, we will make sure that it's clear. I mean, mistakes always happen. In case it's not, you should ask. But this is more for when you have a real data set."
4133.15,4165.94,"the one thing that you would do is probably test different options and see which one performs best in your scenario. Okay, pruning. So one thing after building or during building of the decision tree, it might be that we want to prune parts of it so that to avoid that the decision tree is overfitting or maybe we don't want it to be very complex, right?"
4166.48,4194.7,"So one option is pre-pruning, that is early stopping, and the other is post-pruning. That means we first build completely the tree and then we decide which things to remove. So what can be possible stopping criterion? One can be that you say, okay, I don't have enough instances, right? Before we said I have zero instances, there is nothing I can do."
4194.7,4224.69,"but it might be that, I don't know, you have a data set with 1,000 instances, and then you say, once I get to a subset of 10 instances, I don't want to split anymore. In that case, I will just use the majority label in that subset and won't go through the trouble of splitting. The other thing that you can do is say, okay, I try to do the split, but maybe the split doesn't improve"
4224.82,4254.77,"that much, the entropy, so the information gain is not that high, so you can have a threshold for the information gain and say, okay, if it's not high enough, then I stop splitting again, no matter how many instances I have. So you should consider here that basically if you prune, the tree won't always be consistent with the data, right, because some things will be mislabeled."
4255.15,4285.66,"And why we do that is to generalize and avoid overfitting. Yeah? So we have here like two options. Information gain is too small, let's say, for this node. And here we don't have enough instances. And what we would do is basically we wouldn't consider here the children. There is still, let's say, a difference between the two. Now maybe a bit..."
4285.66,4314.83,"vague, okay, maybe no time for question, but the difference is that here, right, to compute this, you still need to do the split and make the calculations, right? So you still have more computations than you would have here, because here you wouldn't do the computations in the first place. So this one, let's say, would be faster than doing this one."
4316.72,4344.58,"So this is all good, but the problem might be that I cut here, right, because of information gain, but maybe later on actually I can find some really strong dependencies. So we should be careful whether we want to do that or not, and that's why kind of an alternative is the post-pruning, where we first build the entire tree and then we decide"
4344.58,4374.27,"to cut off branches that do not add that much. In order to be able to do this, let's say we need to split our data, not only in training and test data set, but we also need a validation set. And this validation set will be mentioned, let's say, in other lecture as well, so for parameter optimization. And basically, we would then build the tree on the training data set and use the validation set"
4374.27,4405.26,"to see, let's say, which of the instances will be misclassified. Now, this tree here, right, as I said, learned on the training set and the red numbers indicate how many instances would be misclassified if we stopped here in the validation set, right? Not in the training set, in the validation set. And now you're thinking maybe,"
4405.26,4433.95,"Okay, here I know how I decide the label, but here basically it's not that I have a label, I have a feature. The label for this we would decide basically by taking the majority label of the instances in this data set. And now what I can do is I can see maybe whether here the misclassification, does it go lower or higher if I do the split, right?"
4433.95,4466.96,"Here I have 10 misclassifications, but after the split, if I sum this up, I would have 11. So then in that case, it really doesn't make sense to do the split, right? Here, it's a similar story. And sometimes the threshold doesn't even have to be that this one is smaller than this one, but maybe it's just not good enough. Yes? I just take the validation set, right? This is a different set from what we trained on. And then..."
4466.96,4497.25,"As we did in the beginning when I asked, okay, is this spam or ham? You follow the branches, right? I see here which one is the feature first. And then for each instance of the validation set, I test here for that feature. And then I decide do I go left or right, left or right, left or right. And I see for this here, as I said, I take, let's say, if the entire data set contains 100 instances and 80 of them are spam,"
4497.25,4546.45,"this here would be spam without considering any splitting. There are two data sets, but they have the same features and the same target feature. So they have the same, the table would look the same. It is just whether you take different instances in one compared to the other. Can we maybe do this? Yes, yeah. Yes."
4546.8,4572.93,"And finally, we have ensembles. So we don't have a single decision tree, but we have a set of them. And this is like models that should complement each other. And basically, each tree has a vote, and votes might be weighted. So kind of I wanted to illustrate this, but we don't have that much time. So now let's say I give you this instance, so this email."
4572.93,4600.91,"you have to decide whether it's spam or ham, and you only have the ID, right? And now I ask you, which of you think it's spam, right? You don't have information, it's just random guessing. Yeah, thank you, only a few, so some need to do this, right? And then, okay, then I ask which of you think it's ham, right? Then maybe the rest of you, and then basically,"
4600.98,4630.1,"If each of you is a decision tree, altogether you would be an ensemble, right? It can be that I also say, I don't know, those that are data science, right? I have now, for example, here false and true. I give you a few information. And now I can say, those of you that are data science, please close your eyes. And then I show a new feature. And then I ask you to vote."
4630.51,4656.8,"So basically you can make also the decision based on different information that you have, right? And it was spam, right? Because I knew it's spam, it can also be that I have my vote counts as 10 votes, right? So this is what I kind of set with the main idea. And what are the different options? So one option is boosting."
4656.8,4682.7,"And boosting is iteratively changing the dataset based on misclassifications, right? We train one dataset, but then when we want to train the next one, we give more weight to the instances that the first one misclassified. That means the second one will be better in those compared to the first one. And we continue kind of doing this as long as we want to have different models."
4682.7,4712.21,"Then we have bagging. With bagging, we just take a random sum sample of the data set. So this maybe explains it better, right? If for each one now I train a different decision tree, for these two, this decision tree would not see the second and the third instance, this one would not see the first and the third, and so on and so on. So they basically train on a different..."
4712.27,4747.38,"on a different subset. Then we have subspace sampling. Now it's not that we drop instances, but we drop basically features. Yes? It is just that you're not overfitting, right? Every tree has even less information, but another tree can compensate for that one. What? Right? Complexity also grows because you need to train more trees."
4747.38,4778.34,"but it's just that the trees might be simpler. So similar here, we just drop now features, right? Each tree has a different perspective. This basically works with the example that I showed before where I said, okay, maybe some of you can close your eyes and you don't have any information for that feature, right? And then finally, the random forest, it's a combination of sub..."
4778.34,4810.24,"of space sampling and bagging. So basically each tree is missing some of the instances, but also cannot see some of the features. Okay? Good. I see some doing this, so for at least some, it's good. Okay. Yeah, this is just kind of the end for ensembles, where basically now we have multiple trees and we can have, as I said, majority voting."
4810.24,4842.38,"from before, what most of you voted, that would be the prediction that we give. This majority voting can also be weighted if we think that some trees maybe we train better, some are simpler, some are more complex. Okay, now this is the kind of the final part of the lecture. Hopefully we make it, right? Dealing with continuous variables. So until now we only talked about categorical features, but now we kind of explain a bit how do we handle continuous ones."
4842.38,4870.27,"So still same table, rows, instances, features are columns. The only difference is now that we have, let's say, some that are numeric values. The simple solution, and I think last week you talked about binning with the professor, so the simple option would be from this numerical feature, I just create a categorical one by binning the values. But we want to..."
4870.27,4901.66,"give an alternative. Maybe we can do this better. We have the option that the descriptive features are continuous, but also the option that the target feature is continuous and we will consider both separately. So continuous descriptive features, right? We have two here. And the idea is that we can kind of draw them on an axis, right? We can order them."
4901.66,4930.62,"The challenge is to determine where do we split, right? If I just look at the feature and it goes from 0 to 100 and it can also be decimals, then I have infinite options. So how do I decide where to kind of split? We sort, right? We sort the instances based on the descriptive feature and what we then do, we color them."
4930.62,4957.55,"Now this is like visually, but we color them using the target feature and it only makes sense to consider those that are when the target feature changes. I wouldn't want to split here because from the start I would introduce an error. So now I have less options for my splits."
4957.62,4986.1,"So let's say on the example from before, elevation before was categorical, now it's a continuous descriptive feature. What we do is we sort and then we look, okay, at which places do I have this change of the target feature. And one is here, another is here, here and here. And then to decide the value, we can just take the average between the two."
4986.99,5011.79,"So to both we give like equal chance to have values that are close to the one or to the other. Okay, clear? Okay. And now we do what we did before basically, but now so for each one we can"
5011.79,5040.61,"Before, if you remember here, we split based on the descriptive features but now this is only for one feature and then we have different options. Do I split here? Do I split here? Do I split here? Do I split here? And I test for all of them. So I do the split, split the data set, compute entropy, compute weighted entropy and information gain. So I need to test all of them in order that I can know"
5040.61,5075.44,"to which one to choose. In this example, this is the best value. Questions here? Yes? We come to that later. So when we have continuous features, we can have multiple splits, but for one data set, not data set, but for one, let's say, sub data, we first choose one. Right here, it doesn't make sense for me to choose two. I choose one."
5075.66,5106.91,"Split on that one, but maybe later on, deeper in the tree, I can reuse. I can split again. Yes? Yes. So same as before. Okay. Right, so we split elevation here, and now we have two subsets, and basically then we do the same kind of use algorithm on these two subsets. And let's say now the..."
5106.91,5134.21,the resulting decision tree without making the computation would be this and here is the kind of the question comes I have elevation here then I use stream but then I can use elevation again. So this is this is the part that's different from the categorical feature and I just right I can try again. It doesn't make sense to use the same the same split but probably
5134.21,5175.41,if you follow the procedure you won't even have the chance to use the same split yes like allowed might be too strong i would say that that depends really it will depend on the algorithm you're using some might allow it some might not but in general you still need to compete with the other features right so it's not only that you see that one now the target feature is continuous one and
5175.41,5204.27,"Now it doesn't make sense, right? We cannot color now because our target feature is continuous, but we want to find a descriptive feature that would nicely split here, let's say, continuous data. And since now the impurity, we will measure with variance because if we think about in the end, the decision tree, when it has a continuous target feature, the label it returns will be the"
5204.27,5231.66,the average of the instances in that set and then basically the error we can make is really the variance. So now we color the dots using a descriptive feature and the position is given for the target feature. And the idea is now if I split this into multiple levels it's that
5231.66,5258.9,"I want here the variance between the dots to be quite close to each other, right? And let's say I have different now options. I have here a good classification because, as you can see, red really is only in the lowest values. Green is for the middle ones and blue is for the highest ones. Then if I have, let's say, some blue one here and red one here,"
5258.9,5288.34,"This is still a good classification for this feature, but it's not as good as the previous one, right? There are few values that have like split, like changed where we would want them to be. However, if I now see this, this is much worse, right? If I split, like I have a value here and a value here, and basically I also have values here for green, so maybe this is not the best descriptive feature to split on."
5289.04,5316.61,"So what we basically do is we compute the variance for each color and then for the entire thing, for the entire feature, we take the weighted variance for all of the colors. The weighted would be how many green times the variance of green, how many red times the variance of red. The change that we need to do here"
5316.61,5345.07,"is that we do not basically now take the descriptive feature that has maximal information gain, but we take the descriptive feature that has the minimum variance. What we talked about before for continuous descriptive features, we actually change here that we do not, so line 11, we would not remove the feature from the set of features."
5345.07,5376.16,"So overfitting and underfitting, basically, we should be careful because if we continue splitting, the variance will always be the best if every instance is on its own. So we don't want to overfit the data. We would want something like this. This is the risk with variance. It always gets smaller and smaller. So this is something to have in mind. So shortly, one minute, example from the book."
5376.16,5406.03,"So what we have here, basically, we now have this descriptive feature and this one. These are the levels, these are the subsets, right? These are the instances in each subset. And then for these instances, I compute the variance. And then, actually, this was the weight, but I compute the variance here. And then I have the weighted variance. And then for both features, I have a result. And then I can choose the one."
5406.03,5434.54,that has a lower variance this is how that would basically look and as i said if we want to now make a prediction because it's not a categorical feature we would take the average of a leaf okay so this is just kind of a summary which of the parts maybe go in which algorithm there are different variations some have continuous features some have missing values some
5434.54,5463.9,"are just open source implementations, but it just summarizes which of the things that we explained fit were. To conclude, so we talked shortly about supervised learning, and you will have supervised learning also in the next lecture. We talked about decision trees. We learned that they are mostly used with categorical features, but we can adapt them to use continuous ones, and there are many variations possible."
5463.9,5474.93,So this is the literature and we are here. So on Wednesday you have a lecture on regression and Aaron will give the lecture. Thanks a lot.
